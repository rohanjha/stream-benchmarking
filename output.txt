2018-04-25 22:45:44 WARN  Utils:66 - Your hostname, rjha-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
2018-04-25 22:45:44 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2018-04-25 22:45:45 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-04-25 22:45:46 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-04-25 22:45:46 INFO  SparkContext:54 - Submitted application: PythonStreamingNetworkWordCount
2018-04-25 22:45:46 INFO  SecurityManager:54 - Changing view acls to: rjha
2018-04-25 22:45:46 INFO  SecurityManager:54 - Changing modify acls to: rjha
2018-04-25 22:45:46 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-04-25 22:45:46 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-04-25 22:45:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rjha); groups with view permissions: Set(); users  with modify permissions: Set(rjha); groups with modify permissions: Set()
2018-04-25 22:45:47 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40207.
2018-04-25 22:45:47 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-04-25 22:45:47 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-04-25 22:45:47 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-25 22:45:47 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-04-25 22:45:47 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-cb8838a4-1eae-4a9e-8dee-fde6eca1bbb2
2018-04-25 22:45:47 INFO  MemoryStore:54 - MemoryStore started with capacity 413.9 MB
2018-04-25 22:45:47 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-04-25 22:45:47 INFO  log:192 - Logging initialized @4619ms
2018-04-25 22:45:47 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-04-25 22:45:47 INFO  Server:414 - Started @4753ms
2018-04-25 22:45:47 INFO  AbstractConnector:278 - Started ServerConnector@1711e0a3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-04-25 22:45:47 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67c1c0db{/jobs,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6aecd5c3{/jobs/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50e54096{/jobs/job,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49c2b473{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@450c3245{/stages,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f973b82{/stages/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@704019e9{/stages/stage,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@e0aaacf{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef565b6{/stages/pool,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@389b787c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@eb148aa{/storage,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5536d761{/storage/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@bbd0a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63001057{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67f0e085{/environment,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49eaec5{/environment/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a7e6002{/executors,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@391f51b2{/executors/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@598b6adc{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28920fae{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1c514ce{/static,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@645b4d4a{/,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3a69358b{/api,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25083bd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70d448d2{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-25 22:45:47 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.2.15:4040
2018-04-25 22:45:48 INFO  SparkContext:54 - Added file file:/home/rjha/stream-benchmarking-scratch/streaming_test.py at file:/home/rjha/stream-benchmarking-scratch/streaming_test.py with timestamp 1524710748550
2018-04-25 22:45:48 INFO  Utils:54 - Copying /home/rjha/stream-benchmarking-scratch/streaming_test.py to /tmp/spark-a9a98e64-a528-4051-8500-b89c9bf0f7a2/userFiles-7e0dda63-63d6-43bb-9b27-533613ed924e/streaming_test.py
2018-04-25 22:45:48 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-04-25 22:45:48 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45765.
2018-04-25 22:45:48 INFO  NettyBlockTransferService:54 - Server created on 10.0.2.15:45765
2018-04-25 22:45:48 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-25 22:45:48 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.2.15, 45765, None)
2018-04-25 22:45:48 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.2.15:45765 with 413.9 MB RAM, BlockManagerId(driver, 10.0.2.15, 45765, None)
2018-04-25 22:45:48 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.2.15, 45765, None)
2018-04-25 22:45:48 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.0.2.15, 45765, None)
2018-04-25 22:45:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58f20e42{/metrics/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:50 INFO  ReceiverTracker:54 - Starting 1 receivers
2018-04-25 22:45:50 INFO  ReceiverTracker:54 - ReceiverTracker started
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Slide time = 1000 ms
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Storage level = Serialized 1x Replicated
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Checkpoint interval = null
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Remember interval = 1000 ms
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@3a7e9625
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Slide time = 1000 ms
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Storage level = Serialized 1x Replicated
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Checkpoint interval = null
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Remember interval = 1000 ms
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Initialized and validated org.apache.spark.streaming.api.python.PythonTransformedDStream@1258debc
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Slide time = 1000 ms
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Storage level = Serialized 1x Replicated
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Checkpoint interval = null
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Remember interval = 1000 ms
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@5e7aa717
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Slide time = 1000 ms
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Storage level = Serialized 1x Replicated
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Checkpoint interval = null
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Remember interval = 1000 ms
2018-04-25 22:45:50 INFO  SocketInputDStream:54 - Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@3a7e9625
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Slide time = 1000 ms
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Storage level = Serialized 1x Replicated
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Checkpoint interval = null
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Remember interval = 1000 ms
2018-04-25 22:45:50 INFO  PythonTransformedDStream:54 - Initialized and validated org.apache.spark.streaming.api.python.PythonTransformedDStream@1258debc
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Slide time = 1000 ms
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Storage level = Serialized 1x Replicated
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Checkpoint interval = null
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Remember interval = 1000 ms
2018-04-25 22:45:50 INFO  ForEachDStream:54 - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@241e190b
2018-04-25 22:45:50 INFO  ReceiverTracker:54 - Receiver 0 started
2018-04-25 22:45:50 INFO  DAGScheduler:54 - Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
2018-04-25 22:45:50 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (start at NativeMethodAccessorImpl.java:0)
2018-04-25 22:45:50 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:45:50 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:45:50 INFO  RecurringTimer:54 - Started timer for JobGenerator at time 1524710751000
2018-04-25 22:45:50 INFO  JobGenerator:54 - Started JobGenerator at 1524710751000 ms
2018-04-25 22:45:50 INFO  JobScheduler:54 - Started JobScheduler
2018-04-25 22:45:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d2fce4{/streaming,null,AVAILABLE,@Spark}
2018-04-25 22:45:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@675a9618{/streaming/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@42a46489{/streaming/batch,null,AVAILABLE,@Spark}
2018-04-25 22:45:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@33bb7db4{/streaming/batch/json,null,AVAILABLE,@Spark}
2018-04-25 22:45:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72771032{/static/streaming,null,AVAILABLE,@Spark}
2018-04-25 22:45:50 INFO  StreamingContext:54 - StreamingContext started
2018-04-25 22:45:50 INFO  DAGScheduler:54 - Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:613), which has no missing parents
2018-04-25 22:45:51 INFO  JobScheduler:54 - Added jobs for time 1524710751000 ms
2018-04-25 22:45:51 INFO  JobScheduler:54 - Starting job streaming job 1524710751000 ms.0 from job set of time 1524710751000 ms
2018-04-25 22:45:51 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 68.7 KB, free 413.9 MB)
2018-04-25 22:45:51 INFO  deprecation:1173 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2018-04-25 22:45:51 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:51 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:45:51 INFO  DAGScheduler:54 - Job 1 finished: runJob at SparkHadoopWriter.scala:78, took 0.000659 s
2018-04-25 22:45:51 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.8 MB)
2018-04-25 22:45:51 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.2.15:45765 (size: 23.9 KB, free: 413.9 MB)
2018-04-25 22:45:51 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:45:51 INFO  SparkHadoopWriter:54 - Job job_20180425224551_0005 committed.
2018-04-25 22:45:51 INFO  JobScheduler:54 - Finished job streaming job 1524710751000 ms.0 from job set of time 1524710751000 ms
2018-04-25 22:45:51 INFO  JobScheduler:54 - Starting job streaming job 1524710751000 ms.1 from job set of time 1524710751000 ms
2018-04-25 22:45:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:613) (first 15 tasks are for partitions Vector(0))
2018-04-25 22:45:51 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2018-04-25 22:45:51 INFO  SparkContext:54 - Starting job: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257
2018-04-25 22:45:51 INFO  DAGScheduler:54 - Job 2 finished: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257, took 0.000047 s
2018-04-25 22:45:51 INFO  JobScheduler:54 - Finished job streaming job 1524710751000 ms.1 from job set of time 1524710751000 ms
2018-04-25 22:45:51 INFO  JobScheduler:54 - Total delay: 0.849 s for time 1524710751000 ms (execution: 0.611 s)
2018-04-25 22:45:51 INFO  ReceivedBlockTracker:54 - Deleting batches: 
2018-04-25 22:45:51 INFO  InputInfoTracker:54 - remove old batch metadata: 
2018-04-25 22:45:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8442 bytes)
2018-04-25 22:45:52 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-04-25 22:45:52 INFO  JobScheduler:54 - Added jobs for time 1524710752000 ms
2018-04-25 22:45:52 INFO  JobScheduler:54 - Starting job streaming job 1524710752000 ms.0 from job set of time 1524710752000 ms
2018-04-25 22:45:52 INFO  Executor:54 - Fetching file:/home/rjha/stream-benchmarking-scratch/streaming_test.py with timestamp 1524710748550
2018-04-25 22:45:52 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:52 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:45:52 INFO  DAGScheduler:54 - Job 3 finished: runJob at SparkHadoopWriter.scala:78, took 0.000046 s
2018-04-25 22:45:52 INFO  SparkHadoopWriter:54 - Job job_20180425224552_0011 committed.
2018-04-25 22:45:52 INFO  JobScheduler:54 - Finished job streaming job 1524710752000 ms.0 from job set of time 1524710752000 ms
2018-04-25 22:45:52 INFO  JobScheduler:54 - Starting job streaming job 1524710752000 ms.1 from job set of time 1524710752000 ms
2018-04-25 22:45:52 INFO  Utils:54 - /home/rjha/stream-benchmarking-scratch/streaming_test.py has been previously copied to /tmp/spark-a9a98e64-a528-4051-8500-b89c9bf0f7a2/userFiles-7e0dda63-63d6-43bb-9b27-533613ed924e/streaming_test.py
2018-04-25 22:45:52 INFO  SparkContext:54 - Starting job: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257
2018-04-25 22:45:52 INFO  DAGScheduler:54 - Job 4 finished: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257, took 0.000042 s
2018-04-25 22:45:52 INFO  JobScheduler:54 - Finished job streaming job 1524710752000 ms.1 from job set of time 1524710752000 ms
2018-04-25 22:45:52 INFO  JobScheduler:54 - Total delay: 0.378 s for time 1524710752000 ms (execution: 0.347 s)
2018-04-25 22:45:52 INFO  PythonRDD:54 - Removing RDD 2 from persistence list
2018-04-25 22:45:52 INFO  BlockManager:54 - Removing RDD 2
2018-04-25 22:45:52 INFO  BlockRDD:54 - Removing RDD 1 from persistence list
2018-04-25 22:45:52 INFO  SocketInputDStream:54 - Removing blocks of RDD BlockRDD[1] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1524710752000 ms
2018-04-25 22:45:52 INFO  ReceivedBlockTracker:54 - Deleting batches: 
2018-04-25 22:45:52 INFO  InputInfoTracker:54 - remove old batch metadata: 
2018-04-25 22:45:52 INFO  BlockManager:54 - Removing RDD 1
2018-04-25 22:45:52 INFO  RecurringTimer:54 - Started timer for BlockGenerator at time 1524710752800
2018-04-25 22:45:52 INFO  BlockGenerator:54 - Started BlockGenerator
2018-04-25 22:45:52 INFO  BlockGenerator:54 - Started block pushing thread
2018-04-25 22:45:52 INFO  ReceiverTracker:54 - Registered receiver for stream 0 from 10.0.2.15:40207
2018-04-25 22:45:52 INFO  ReceiverSupervisorImpl:54 - Starting receiver 0
2018-04-25 22:45:52 INFO  SocketReceiver:54 - Connecting to localhost:9998
2018-04-25 22:45:52 INFO  SocketReceiver:54 - Connected to localhost:9998
2018-04-25 22:45:52 INFO  ReceiverSupervisorImpl:54 - Called receiver 0 onStart
2018-04-25 22:45:52 INFO  ReceiverSupervisorImpl:54 - Waiting for receiver to be stopped
2018-04-25 22:45:52 INFO  MemoryStore:54 - Block input-0-1524710752600 stored as bytes in memory (estimated size 175.0 B, free 413.8 MB)
2018-04-25 22:45:52 INFO  BlockManagerInfo:54 - Added input-0-1524710752600 in memory on 10.0.2.15:45765 (size: 175.0 B, free: 413.9 MB)
2018-04-25 22:45:52 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:52 WARN  BlockManager:66 - Block input-0-1524710752600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:53 INFO  BlockGenerator:54 - Pushed block input-0-1524710752600
2018-04-25 22:45:53 INFO  JobScheduler:54 - Added jobs for time 1524710753000 ms
2018-04-25 22:45:53 INFO  JobScheduler:54 - Starting job streaming job 1524710753000 ms.0 from job set of time 1524710753000 ms
2018-04-25 22:45:53 INFO  MemoryStore:54 - Block input-0-1524710752800 stored as bytes in memory (estimated size 167.0 B, free 413.8 MB)
2018-04-25 22:45:53 INFO  BlockManagerInfo:54 - Added input-0-1524710752800 in memory on 10.0.2.15:45765 (size: 167.0 B, free: 413.9 MB)
2018-04-25 22:45:53 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:53 WARN  BlockManager:66 - Block input-0-1524710752800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:53 INFO  BlockGenerator:54 - Pushed block input-0-1524710752800
2018-04-25 22:45:53 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:53 INFO  MemoryStore:54 - Block input-0-1524710753000 stored as bytes in memory (estimated size 426.0 B, free 413.8 MB)
2018-04-25 22:45:53 INFO  BlockManagerInfo:54 - Added input-0-1524710753000 in memory on 10.0.2.15:45765 (size: 426.0 B, free: 413.9 MB)
2018-04-25 22:45:53 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:53 WARN  BlockManager:66 - Block input-0-1524710753000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:53 INFO  BlockGenerator:54 - Pushed block input-0-1524710753000
2018-04-25 22:45:53 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:45:53 INFO  DAGScheduler:54 - Job 5 finished: runJob at SparkHadoopWriter.scala:78, took 0.000045 s
2018-04-25 22:45:53 INFO  SparkHadoopWriter:54 - Job job_20180425224553_0017 committed.
2018-04-25 22:45:53 INFO  JobScheduler:54 - Finished job streaming job 1524710753000 ms.0 from job set of time 1524710753000 ms
2018-04-25 22:45:53 INFO  JobScheduler:54 - Starting job streaming job 1524710753000 ms.1 from job set of time 1524710753000 ms
2018-04-25 22:45:53 INFO  SparkContext:54 - Starting job: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257
2018-04-25 22:45:53 INFO  DAGScheduler:54 - Job 6 finished: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257, took 0.000054 s
2018-04-25 22:45:53 INFO  JobScheduler:54 - Finished job streaming job 1524710753000 ms.1 from job set of time 1524710753000 ms
2018-04-25 22:45:53 INFO  JobScheduler:54 - Total delay: 0.354 s for time 1524710753000 ms (execution: 0.266 s)
2018-04-25 22:45:53 INFO  PythonRDD:54 - Removing RDD 8 from persistence list
2018-04-25 22:45:53 INFO  BlockManager:54 - Removing RDD 8
2018-04-25 22:45:53 INFO  BlockRDD:54 - Removing RDD 7 from persistence list
2018-04-25 22:45:53 INFO  BlockManager:54 - Removing RDD 7
2018-04-25 22:45:53 INFO  SocketInputDStream:54 - Removing blocks of RDD BlockRDD[7] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1524710753000 ms
2018-04-25 22:45:53 INFO  ReceivedBlockTracker:54 - Deleting batches: 1524710751000 ms
2018-04-25 22:45:53 INFO  InputInfoTracker:54 - remove old batch metadata: 1524710751000 ms
2018-04-25 22:45:53 INFO  MemoryStore:54 - Block input-0-1524710753200 stored as bytes in memory (estimated size 386.0 B, free 413.8 MB)
2018-04-25 22:45:53 INFO  BlockManagerInfo:54 - Added input-0-1524710753200 in memory on 10.0.2.15:45765 (size: 386.0 B, free: 413.9 MB)
2018-04-25 22:45:53 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:53 WARN  BlockManager:66 - Block input-0-1524710753200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:53 INFO  BlockGenerator:54 - Pushed block input-0-1524710753200
2018-04-25 22:45:53 INFO  MemoryStore:54 - Block input-0-1524710753400 stored as bytes in memory (estimated size 311.0 B, free 413.8 MB)
2018-04-25 22:45:53 INFO  BlockManagerInfo:54 - Added input-0-1524710753400 in memory on 10.0.2.15:45765 (size: 311.0 B, free: 413.9 MB)
2018-04-25 22:45:53 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:53 WARN  BlockManager:66 - Block input-0-1524710753400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:53 INFO  BlockGenerator:54 - Pushed block input-0-1524710753400
2018-04-25 22:45:53 INFO  MemoryStore:54 - Block input-0-1524710753600 stored as bytes in memory (estimated size 401.0 B, free 413.8 MB)
2018-04-25 22:45:53 INFO  BlockManagerInfo:54 - Added input-0-1524710753600 in memory on 10.0.2.15:45765 (size: 401.0 B, free: 413.9 MB)
2018-04-25 22:45:53 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:53 WARN  BlockManager:66 - Block input-0-1524710753600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:53 INFO  BlockGenerator:54 - Pushed block input-0-1524710753600
2018-04-25 22:45:54 INFO  MemoryStore:54 - Block input-0-1524710753800 stored as bytes in memory (estimated size 395.0 B, free 413.8 MB)
2018-04-25 22:45:54 INFO  BlockManagerInfo:54 - Added input-0-1524710753800 in memory on 10.0.2.15:45765 (size: 395.0 B, free: 413.9 MB)
2018-04-25 22:45:54 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:54 WARN  BlockManager:66 - Block input-0-1524710753800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:54 INFO  BlockGenerator:54 - Pushed block input-0-1524710753800
2018-04-25 22:45:54 INFO  JobScheduler:54 - Starting job streaming job 1524710754000 ms.0 from job set of time 1524710754000 ms
2018-04-25 22:45:54 INFO  JobScheduler:54 - Added jobs for time 1524710754000 ms
2018-04-25 22:45:54 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:54 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:45:54 INFO  DAGScheduler:54 - Got job 7 (runJob at SparkHadoopWriter.scala:78) with 6 output partitions
2018-04-25 22:45:54 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (runJob at SparkHadoopWriter.scala:78)
2018-04-25 22:45:54 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:45:54 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:45:54 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[23] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
2018-04-25 22:45:54 INFO  MemoryStore:54 - Block input-0-1524710754000 stored as bytes in memory (estimated size 406.0 B, free 413.8 MB)
2018-04-25 22:45:54 INFO  BlockManagerInfo:54 - Added input-0-1524710754000 in memory on 10.0.2.15:45765 (size: 406.0 B, free: 413.9 MB)
2018-04-25 22:45:54 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:54 WARN  BlockManager:66 - Block input-0-1524710754000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:54 INFO  BlockGenerator:54 - Pushed block input-0-1524710754000
2018-04-25 22:45:54 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 75.4 KB, free 413.8 MB)
2018-04-25 22:45:54 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 27.9 KB, free 413.7 MB)
2018-04-25 22:45:54 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.2.15:45765 (size: 27.9 KB, free: 413.9 MB)
2018-04-25 22:45:54 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:45:54 INFO  DAGScheduler:54 - Submitting 6 missing tasks from ResultStage 1 (MapPartitionsRDD[23] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2018-04-25 22:45:54 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 6 tasks
2018-04-25 22:45:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:45:54 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2018-04-25 22:45:54 INFO  BlockManager:54 - Found block input-0-1524710752600 locally
2018-04-25 22:45:54 INFO  MemoryStore:54 - Block input-0-1524710754200 stored as bytes in memory (estimated size 406.0 B, free 413.7 MB)
2018-04-25 22:45:54 INFO  BlockManagerInfo:54 - Added input-0-1524710754200 in memory on 10.0.2.15:45765 (size: 406.0 B, free: 413.9 MB)
2018-04-25 22:45:54 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:54 WARN  BlockManager:66 - Block input-0-1524710754200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:54 INFO  BlockGenerator:54 - Pushed block input-0-1524710754200
2018-04-25 22:45:54 INFO  MemoryStore:54 - Block input-0-1524710754400 stored as bytes in memory (estimated size 403.0 B, free 413.7 MB)
2018-04-25 22:45:54 INFO  BlockManagerInfo:54 - Added input-0-1524710754400 in memory on 10.0.2.15:45765 (size: 403.0 B, free: 413.9 MB)
2018-04-25 22:45:54 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:54 WARN  BlockManager:66 - Block input-0-1524710754400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:54 INFO  BlockGenerator:54 - Pushed block input-0-1524710754400
2018-04-25 22:45:54 INFO  MemoryStore:54 - Block input-0-1524710754600 stored as bytes in memory (estimated size 411.0 B, free 413.7 MB)
2018-04-25 22:45:54 INFO  BlockManagerInfo:54 - Added input-0-1524710754600 in memory on 10.0.2.15:45765 (size: 411.0 B, free: 413.9 MB)
2018-04-25 22:45:54 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:54 WARN  BlockManager:66 - Block input-0-1524710754600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:54 INFO  BlockGenerator:54 - Pushed block input-0-1524710754600
2018-04-25 22:45:54 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:54 INFO  PythonRunner:54 - Times: total = 551, boot = 522, init = 29, finish = 0
2018-04-25 22:45:55 INFO  MemoryStore:54 - Block input-0-1524710754800 stored as bytes in memory (estimated size 405.0 B, free 413.7 MB)
2018-04-25 22:45:55 INFO  BlockManagerInfo:54 - Added input-0-1524710754800 in memory on 10.0.2.15:45765 (size: 405.0 B, free: 413.9 MB)
2018-04-25 22:45:55 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:55 WARN  BlockManager:66 - Block input-0-1524710754800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:55 INFO  BlockGenerator:54 - Pushed block input-0-1524710754800
2018-04-25 22:45:55 INFO  JobScheduler:54 - Added jobs for time 1524710755000 ms
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 40, boot = 5, init = 35, finish = 0
2018-04-25 22:45:55 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224554_0023_m_000000_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710754000/_temporary/0/task_20180425224554_0023_m_000000
2018-04-25 22:45:55 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224554_0023_m_000000_0: Committed
2018-04-25 22:45:55 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1658 bytes result sent to driver
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:45:55 INFO  MemoryStore:54 - Block input-0-1524710755000 stored as bytes in memory (estimated size 399.0 B, free 413.7 MB)
2018-04-25 22:45:55 INFO  BlockManagerInfo:54 - Added input-0-1524710755000 in memory on 10.0.2.15:45765 (size: 399.0 B, free: 413.9 MB)
2018-04-25 22:45:55 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 2)
2018-04-25 22:45:55 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:55 WARN  BlockManager:66 - Block input-0-1524710755000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:55 INFO  BlockGenerator:54 - Pushed block input-0-1524710755000
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 928 ms on localhost (executor driver) (1/6)
2018-04-25 22:45:55 INFO  BlockManager:54 - Found block input-0-1524710752800 locally
2018-04-25 22:45:55 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 59, boot = -176, init = 234, finish = 1
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 47, boot = -192, init = 239, finish = 0
2018-04-25 22:45:55 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224554_0023_m_000001_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710754000/_temporary/0/task_20180425224554_0023_m_000001
2018-04-25 22:45:55 INFO  MemoryStore:54 - Block input-0-1524710755200 stored as bytes in memory (estimated size 407.0 B, free 413.7 MB)
2018-04-25 22:45:55 INFO  BlockManagerInfo:54 - Added input-0-1524710755200 in memory on 10.0.2.15:45765 (size: 407.0 B, free: 413.9 MB)
2018-04-25 22:45:55 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:55 WARN  BlockManager:66 - Block input-0-1524710755200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:55 INFO  BlockGenerator:54 - Pushed block input-0-1524710755200
2018-04-25 22:45:55 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224554_0023_m_000001_0: Committed
2018-04-25 22:45:55 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 2). 1572 bytes result sent to driver
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:45:55 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 3)
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 2) in 239 ms on localhost (executor driver) (2/6)
2018-04-25 22:45:55 INFO  BlockManager:54 - Found block input-0-1524710753000 locally
2018-04-25 22:45:55 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 59, boot = -121, init = 179, finish = 1
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 42, boot = -143, init = 185, finish = 0
2018-04-25 22:45:55 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224554_0023_m_000002_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710754000/_temporary/0/task_20180425224554_0023_m_000002
2018-04-25 22:45:55 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224554_0023_m_000002_0: Committed
2018-04-25 22:45:55 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 3). 1572 bytes result sent to driver
2018-04-25 22:45:55 INFO  MemoryStore:54 - Block input-0-1524710755400 stored as bytes in memory (estimated size 402.0 B, free 413.7 MB)
2018-04-25 22:45:55 INFO  BlockManagerInfo:54 - Added input-0-1524710755400 in memory on 10.0.2.15:45765 (size: 402.0 B, free: 413.9 MB)
2018-04-25 22:45:55 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:55 WARN  BlockManager:66 - Block input-0-1524710755400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:55 INFO  BlockGenerator:54 - Pushed block input-0-1524710755400
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 3) in 218 ms on localhost (executor driver) (3/6)
2018-04-25 22:45:55 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 4)
2018-04-25 22:45:55 INFO  BlockManager:54 - Found block input-0-1524710753200 locally
2018-04-25 22:45:55 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 48, boot = -109, init = 157, finish = 0
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 55, boot = -126, init = 180, finish = 1
2018-04-25 22:45:55 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224554_0023_m_000003_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710754000/_temporary/0/task_20180425224554_0023_m_000003
2018-04-25 22:45:55 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224554_0023_m_000003_0: Committed
2018-04-25 22:45:55 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 4). 1572 bytes result sent to driver
2018-04-25 22:45:55 INFO  MemoryStore:54 - Block input-0-1524710755600 stored as bytes in memory (estimated size 408.0 B, free 413.7 MB)
2018-04-25 22:45:55 INFO  BlockManagerInfo:54 - Added input-0-1524710755600 in memory on 10.0.2.15:45765 (size: 408.0 B, free: 413.9 MB)
2018-04-25 22:45:55 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:55 WARN  BlockManager:66 - Block input-0-1524710755600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:55 INFO  BlockGenerator:54 - Pushed block input-0-1524710755600
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Starting task 4.0 in stage 1.0 (TID 5, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:45:55 INFO  Executor:54 - Running task 4.0 in stage 1.0 (TID 5)
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 4) in 214 ms on localhost (executor driver) (4/6)
2018-04-25 22:45:55 INFO  BlockManager:54 - Found block input-0-1524710753400 locally
2018-04-25 22:45:55 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 55, boot = -18, init = 72, finish = 1
2018-04-25 22:45:55 INFO  PythonRunner:54 - Times: total = 50, boot = -37, init = 87, finish = 0
2018-04-25 22:45:55 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224554_0023_m_000004_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710754000/_temporary/0/task_20180425224554_0023_m_000004
2018-04-25 22:45:55 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224554_0023_m_000004_0: Committed
2018-04-25 22:45:55 INFO  Executor:54 - Finished task 4.0 in stage 1.0 (TID 5). 1572 bytes result sent to driver
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Starting task 5.0 in stage 1.0 (TID 6, localhost, executor driver, partition 5, ANY, 7772 bytes)
2018-04-25 22:45:55 INFO  TaskSetManager:54 - Finished task 4.0 in stage 1.0 (TID 5) in 159 ms on localhost (executor driver) (5/6)
2018-04-25 22:45:55 INFO  Executor:54 - Running task 5.0 in stage 1.0 (TID 6)
2018-04-25 22:45:56 INFO  MemoryStore:54 - Block input-0-1524710755800 stored as bytes in memory (estimated size 405.0 B, free 413.7 MB)
2018-04-25 22:45:56 INFO  BlockManagerInfo:54 - Added input-0-1524710755800 in memory on 10.0.2.15:45765 (size: 405.0 B, free: 413.9 MB)
2018-04-25 22:45:56 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:56 WARN  BlockManager:66 - Block input-0-1524710755800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:56 INFO  BlockGenerator:54 - Pushed block input-0-1524710755800
2018-04-25 22:45:56 INFO  BlockManager:54 - Found block input-0-1524710753600 locally
2018-04-25 22:45:56 INFO  JobScheduler:54 - Added jobs for time 1524710756000 ms
2018-04-25 22:45:56 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:56 INFO  PythonRunner:54 - Times: total = 56, boot = -104, init = 159, finish = 1
2018-04-25 22:45:56 INFO  PythonRunner:54 - Times: total = 42, boot = -94, init = 136, finish = 0
2018-04-25 22:45:56 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224554_0023_m_000005_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710754000/_temporary/0/task_20180425224554_0023_m_000005
2018-04-25 22:45:56 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224554_0023_m_000005_0: Committed
2018-04-25 22:45:56 INFO  Executor:54 - Finished task 5.0 in stage 1.0 (TID 6). 1572 bytes result sent to driver
2018-04-25 22:45:56 INFO  TaskSetManager:54 - Finished task 5.0 in stage 1.0 (TID 6) in 201 ms on localhost (executor driver) (6/6)
2018-04-25 22:45:56 INFO  DAGScheduler:54 - ResultStage 1 (runJob at SparkHadoopWriter.scala:78) finished in 1.968 s
2018-04-25 22:45:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-04-25 22:45:56 INFO  MemoryStore:54 - Block input-0-1524710756000 stored as bytes in memory (estimated size 382.0 B, free 413.7 MB)
2018-04-25 22:45:56 INFO  BlockManagerInfo:54 - Added input-0-1524710756000 in memory on 10.0.2.15:45765 (size: 382.0 B, free: 413.9 MB)
2018-04-25 22:45:56 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:56 WARN  BlockManager:66 - Block input-0-1524710756000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:56 INFO  BlockGenerator:54 - Pushed block input-0-1524710756000
2018-04-25 22:45:56 INFO  DAGScheduler:54 - Job 7 finished: runJob at SparkHadoopWriter.scala:78, took 2.079898 s
2018-04-25 22:45:56 INFO  SparkHadoopWriter:54 - Job job_20180425224554_0023 committed.
2018-04-25 22:45:56 INFO  JobScheduler:54 - Finished job streaming job 1524710754000 ms.0 from job set of time 1524710754000 ms
2018-04-25 22:45:56 INFO  JobScheduler:54 - Starting job streaming job 1524710754000 ms.1 from job set of time 1524710754000 ms
2018-04-25 22:45:56 INFO  SparkContext:54 - Starting job: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257
2018-04-25 22:45:56 INFO  DAGScheduler:54 - Got job 8 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) with 6 output partitions
2018-04-25 22:45:56 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257)
2018-04-25 22:45:56 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:45:56 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:45:56 INFO  DAGScheduler:54 - Submitting ResultStage 2 (PythonRDD[28] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257), which has no missing parents
2018-04-25 22:45:56 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 7.1 KB, free 413.7 MB)
2018-04-25 22:45:56 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.1 KB, free 413.7 MB)
2018-04-25 22:45:56 INFO  MemoryStore:54 - Block input-0-1524710756200 stored as bytes in memory (estimated size 404.0 B, free 413.7 MB)
2018-04-25 22:45:56 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.0.2.15:45765 (size: 4.1 KB, free: 413.9 MB)
2018-04-25 22:45:56 INFO  BlockManagerInfo:54 - Added input-0-1524710756200 in memory on 10.0.2.15:45765 (size: 404.0 B, free: 413.9 MB)
2018-04-25 22:45:56 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:56 WARN  BlockManager:66 - Block input-0-1524710756200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:56 INFO  BlockGenerator:54 - Pushed block input-0-1524710756200
2018-04-25 22:45:56 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:45:56 INFO  DAGScheduler:54 - Submitting 6 missing tasks from ResultStage 2 (PythonRDD[28] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2018-04-25 22:45:56 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 6 tasks
2018-04-25 22:45:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 7, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:45:56 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 7)
2018-04-25 22:45:56 INFO  BlockManager:54 - Found block input-0-1524710752600 locally
2018-04-25 22:45:56 INFO  PythonRunner:54 - Times: total = 56, boot = -274, init = 330, finish = 0
2018-04-25 22:45:56 INFO  PythonRunner:54 - Times: total = 48, boot = -283, init = 331, finish = 0
2018-04-25 22:45:56 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 7). 1310 bytes result sent to driver
2018-04-25 22:45:56 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 8, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:45:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 7) in 107 ms on localhost (executor driver) (1/6)
2018-04-25 22:45:56 INFO  Executor:54 - Running task 1.0 in stage 2.0 (TID 8)
2018-04-25 22:45:56 INFO  BlockManager:54 - Found block input-0-1524710752800 locally
2018-04-25 22:45:56 INFO  PythonRunner:54 - Times: total = 160, boot = -55, init = 215, finish = 0
2018-04-25 22:45:56 INFO  PythonRunner:54 - Times: total = 150, boot = 139, init = 11, finish = 0
2018-04-25 22:45:56 INFO  MemoryStore:54 - Block input-0-1524710756400 stored as bytes in memory (estimated size 386.0 B, free 413.7 MB)
2018-04-25 22:45:56 INFO  BlockManagerInfo:54 - Added input-0-1524710756400 in memory on 10.0.2.15:45765 (size: 386.0 B, free: 413.9 MB)
2018-04-25 22:45:56 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:56 WARN  BlockManager:66 - Block input-0-1524710756400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:56 INFO  BlockGenerator:54 - Pushed block input-0-1524710756400
2018-04-25 22:45:56 INFO  Executor:54 - Finished task 1.0 in stage 2.0 (TID 8). 1267 bytes result sent to driver
2018-04-25 22:45:56 INFO  TaskSetManager:54 - Starting task 2.0 in stage 2.0 (TID 9, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:45:56 INFO  TaskSetManager:54 - Finished task 1.0 in stage 2.0 (TID 8) in 273 ms on localhost (executor driver) (2/6)
2018-04-25 22:45:56 INFO  Executor:54 - Running task 2.0 in stage 2.0 (TID 9)
2018-04-25 22:45:56 INFO  BlockManager:54 - Found block input-0-1524710753000 locally
2018-04-25 22:45:56 INFO  MemoryStore:54 - Block input-0-1524710756600 stored as bytes in memory (estimated size 366.0 B, free 413.7 MB)
2018-04-25 22:45:56 INFO  BlockManagerInfo:54 - Added input-0-1524710756600 in memory on 10.0.2.15:45765 (size: 366.0 B, free: 413.9 MB)
2018-04-25 22:45:56 INFO  PythonRunner:54 - Times: total = 54, boot = -95, init = 149, finish = 0
2018-04-25 22:45:56 INFO  PythonRunner:54 - Times: total = 65, boot = 65, init = 0, finish = 0
2018-04-25 22:45:56 INFO  Executor:54 - Finished task 2.0 in stage 2.0 (TID 9). 1267 bytes result sent to driver
2018-04-25 22:45:56 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:56 WARN  BlockManager:66 - Block input-0-1524710756600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:56 INFO  BlockGenerator:54 - Pushed block input-0-1524710756600
2018-04-25 22:45:56 INFO  TaskSetManager:54 - Starting task 3.0 in stage 2.0 (TID 10, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:45:56 INFO  TaskSetManager:54 - Finished task 2.0 in stage 2.0 (TID 9) in 208 ms on localhost (executor driver) (3/6)
2018-04-25 22:45:56 INFO  Executor:54 - Running task 3.0 in stage 2.0 (TID 10)
2018-04-25 22:45:56 INFO  BlockManager:54 - Found block input-0-1524710753200 locally
2018-04-25 22:45:57 INFO  MemoryStore:54 - Block input-0-1524710756800 stored as bytes in memory (estimated size 346.0 B, free 413.7 MB)
2018-04-25 22:45:57 INFO  BlockManagerInfo:54 - Added input-0-1524710756800 in memory on 10.0.2.15:45765 (size: 346.0 B, free: 413.9 MB)
2018-04-25 22:45:57 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:57 WARN  BlockManager:66 - Block input-0-1524710756800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:57 INFO  BlockGenerator:54 - Pushed block input-0-1524710756800
2018-04-25 22:45:57 INFO  PythonRunner:54 - Times: total = 80, boot = -86, init = 166, finish = 0
2018-04-25 22:45:57 INFO  PythonRunner:54 - Times: total = 193, boot = 163, init = 0, finish = 30
2018-04-25 22:45:57 INFO  Executor:54 - Finished task 3.0 in stage 2.0 (TID 10). 1267 bytes result sent to driver
2018-04-25 22:45:57 INFO  TaskSetManager:54 - Starting task 4.0 in stage 2.0 (TID 11, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:45:57 INFO  MemoryStore:54 - Block input-0-1524710757000 stored as bytes in memory (estimated size 342.0 B, free 413.7 MB)
2018-04-25 22:45:57 INFO  TaskSetManager:54 - Finished task 3.0 in stage 2.0 (TID 10) in 238 ms on localhost (executor driver) (4/6)
2018-04-25 22:45:57 INFO  Executor:54 - Running task 4.0 in stage 2.0 (TID 11)
2018-04-25 22:45:57 INFO  BlockManager:54 - Found block input-0-1524710753400 locally
2018-04-25 22:45:57 INFO  BlockManagerInfo:54 - Added input-0-1524710757000 in memory on 10.0.2.15:45765 (size: 342.0 B, free: 413.9 MB)
2018-04-25 22:45:57 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:57 WARN  BlockManager:66 - Block input-0-1524710757000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:57 INFO  BlockGenerator:54 - Pushed block input-0-1524710757000
2018-04-25 22:45:57 INFO  JobScheduler:54 - Added jobs for time 1524710757000 ms
2018-04-25 22:45:57 INFO  PythonRunner:54 - Times: total = 59, boot = 12, init = 46, finish = 1
2018-04-25 22:45:57 INFO  PythonRunner:54 - Times: total = 54, boot = 35, init = 19, finish = 0
2018-04-25 22:45:57 INFO  Executor:54 - Finished task 4.0 in stage 2.0 (TID 11). 1267 bytes result sent to driver
2018-04-25 22:45:57 INFO  TaskSetManager:54 - Starting task 5.0 in stage 2.0 (TID 12, localhost, executor driver, partition 5, ANY, 7772 bytes)
2018-04-25 22:45:57 INFO  Executor:54 - Running task 5.0 in stage 2.0 (TID 12)
2018-04-25 22:45:57 INFO  TaskSetManager:54 - Finished task 4.0 in stage 2.0 (TID 11) in 182 ms on localhost (executor driver) (5/6)
2018-04-25 22:45:57 INFO  BlockManager:54 - Found block input-0-1524710753600 locally
2018-04-25 22:45:57 INFO  MemoryStore:54 - Block input-0-1524710757200 stored as bytes in memory (estimated size 325.0 B, free 413.7 MB)
2018-04-25 22:45:57 INFO  BlockManagerInfo:54 - Added input-0-1524710757200 in memory on 10.0.2.15:45765 (size: 325.0 B, free: 413.9 MB)
2018-04-25 22:45:57 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:57 WARN  BlockManager:66 - Block input-0-1524710757200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:57 INFO  BlockGenerator:54 - Pushed block input-0-1524710757200
2018-04-25 22:45:57 INFO  PythonRunner:54 - Times: total = 179, boot = 103, init = 75, finish = 1
2018-04-25 22:45:57 INFO  PythonRunner:54 - Times: total = 60, boot = 5, init = 54, finish = 1
2018-04-25 22:45:57 INFO  Executor:54 - Finished task 5.0 in stage 2.0 (TID 12). 1310 bytes result sent to driver
2018-04-25 22:45:57 INFO  MemoryStore:54 - Block input-0-1524710757400 stored as bytes in memory (estimated size 346.0 B, free 413.7 MB)
2018-04-25 22:45:57 INFO  BlockManagerInfo:54 - Added input-0-1524710757400 in memory on 10.0.2.15:45765 (size: 346.0 B, free: 413.9 MB)
2018-04-25 22:45:57 INFO  TaskSetManager:54 - Finished task 5.0 in stage 2.0 (TID 12) in 259 ms on localhost (executor driver) (6/6)
2018-04-25 22:45:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-04-25 22:45:57 INFO  DAGScheduler:54 - ResultStage 2 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) finished in 1.263 s
2018-04-25 22:45:57 INFO  DAGScheduler:54 - Job 8 finished: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257, took 1.287723 s
2018-04-25 22:45:57 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:57 WARN  BlockManager:66 - Block input-0-1524710757400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:57 INFO  BlockGenerator:54 - Pushed block input-0-1524710757400
2018-04-25 22:45:57 INFO  JobScheduler:54 - Finished job streaming job 1524710754000 ms.1 from job set of time 1524710754000 ms
2018-04-25 22:45:57 INFO  JobScheduler:54 - Total delay: 3.713 s for time 1524710754000 ms (execution: 3.653 s)
2018-04-25 22:45:57 INFO  JobScheduler:54 - Starting job streaming job 1524710755000 ms.0 from job set of time 1524710755000 ms
2018-04-25 22:45:57 INFO  PythonRDD:54 - Removing RDD 14 from persistence list
2018-04-25 22:45:57 INFO  BlockManager:54 - Removing RDD 14
2018-04-25 22:45:57 INFO  BlockRDD:54 - Removing RDD 13 from persistence list
2018-04-25 22:45:57 INFO  BlockManager:54 - Removing RDD 13
2018-04-25 22:45:57 INFO  SocketInputDStream:54 - Removing blocks of RDD BlockRDD[13] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1524710754000 ms
2018-04-25 22:45:57 INFO  ReceivedBlockTracker:54 - Deleting batches: 1524710752000 ms
2018-04-25 22:45:57 INFO  InputInfoTracker:54 - remove old batch metadata: 1524710752000 ms
2018-04-25 22:45:57 INFO  MemoryStore:54 - Block input-0-1524710757600 stored as bytes in memory (estimated size 344.0 B, free 413.7 MB)
2018-04-25 22:45:57 INFO  BlockManagerInfo:54 - Added input-0-1524710757600 in memory on 10.0.2.15:45765 (size: 344.0 B, free: 413.9 MB)
2018-04-25 22:45:57 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:57 WARN  BlockManager:66 - Block input-0-1524710757600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:57 INFO  BlockGenerator:54 - Pushed block input-0-1524710757600
2018-04-25 22:45:57 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:57 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:45:57 INFO  DAGScheduler:54 - Got job 9 (runJob at SparkHadoopWriter.scala:78) with 5 output partitions
2018-04-25 22:45:57 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (runJob at SparkHadoopWriter.scala:78)
2018-04-25 22:45:57 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:45:57 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:45:57 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[33] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
2018-04-25 22:45:58 INFO  MemoryStore:54 - Block input-0-1524710757800 stored as bytes in memory (estimated size 406.0 B, free 413.7 MB)
2018-04-25 22:45:58 INFO  BlockManagerInfo:54 - Added input-0-1524710757800 in memory on 10.0.2.15:45765 (size: 406.0 B, free: 413.9 MB)
2018-04-25 22:45:58 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:58 WARN  BlockManager:66 - Block input-0-1524710757800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:58 INFO  BlockGenerator:54 - Pushed block input-0-1524710757800
2018-04-25 22:45:58 INFO  JobScheduler:54 - Added jobs for time 1524710758000 ms
2018-04-25 22:45:58 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 75.4 KB, free 413.6 MB)
2018-04-25 22:45:58 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 27.9 KB, free 413.6 MB)
2018-04-25 22:45:58 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.0.2.15:45765 (size: 27.9 KB, free: 413.8 MB)
2018-04-25 22:45:58 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:45:58 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[33] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:45:58 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 5 tasks
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 13, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:45:58 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 13)
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 71
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 61
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 67
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 54
2018-04-25 22:45:58 INFO  BlockManager:54 - Found block input-0-1524710753800 locally
2018-04-25 22:45:58 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:58 INFO  PythonRunner:54 - Times: total = 51, boot = -351, init = 402, finish = 0
2018-04-25 22:45:58 INFO  MemoryStore:54 - Block input-0-1524710758000 stored as bytes in memory (estimated size 364.0 B, free 413.6 MB)
2018-04-25 22:45:58 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 10.0.2.15:45765 in memory (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:45:58 INFO  BlockManagerInfo:54 - Added input-0-1524710758000 in memory on 10.0.2.15:45765 (size: 364.0 B, free: 413.8 MB)
2018-04-25 22:45:58 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:58 WARN  BlockManager:66 - Block input-0-1524710758000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:58 INFO  BlockGenerator:54 - Pushed block input-0-1524710758000
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 57
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 66
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 52
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 59
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 62
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 72
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 64
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 51
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 53
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 69
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 56
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 73
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 60
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 55
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 65
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 75
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 74
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 68
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 58
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 70
2018-04-25 22:45:58 INFO  ContextCleaner:54 - Cleaned accumulator 63
2018-04-25 22:45:58 INFO  PythonRunner:54 - Times: total = 72, boot = -390, init = 462, finish = 0
2018-04-25 22:45:58 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224557_0033_m_000000_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710755000/_temporary/0/task_20180425224557_0033_m_000000
2018-04-25 22:45:58 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224557_0033_m_000000_0: Committed
2018-04-25 22:45:58 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 13). 1615 bytes result sent to driver
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 14, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 13) in 226 ms on localhost (executor driver) (1/5)
2018-04-25 22:45:58 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 14)
2018-04-25 22:45:58 INFO  BlockManager:54 - Found block input-0-1524710754000 locally
2018-04-25 22:45:58 INFO  MemoryStore:54 - Block input-0-1524710758200 stored as bytes in memory (estimated size 444.0 B, free 413.6 MB)
2018-04-25 22:45:58 INFO  BlockManagerInfo:54 - Added input-0-1524710758200 in memory on 10.0.2.15:45765 (size: 444.0 B, free: 413.8 MB)
2018-04-25 22:45:58 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:58 WARN  BlockManager:66 - Block input-0-1524710758200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:58 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:58 INFO  BlockGenerator:54 - Pushed block input-0-1524710758200
2018-04-25 22:45:58 INFO  PythonRunner:54 - Times: total = 55, boot = -130, init = 185, finish = 0
2018-04-25 22:45:58 INFO  PythonRunner:54 - Times: total = 177, boot = -112, init = 289, finish = 0
2018-04-25 22:45:58 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224557_0033_m_000001_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710755000/_temporary/0/task_20180425224557_0033_m_000001
2018-04-25 22:45:58 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224557_0033_m_000001_0: Committed
2018-04-25 22:45:58 INFO  MemoryStore:54 - Block input-0-1524710758400 stored as bytes in memory (estimated size 317.0 B, free 413.6 MB)
2018-04-25 22:45:58 INFO  BlockManagerInfo:54 - Added input-0-1524710758400 in memory on 10.0.2.15:45765 (size: 317.0 B, free: 413.8 MB)
2018-04-25 22:45:58 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:58 WARN  BlockManager:66 - Block input-0-1524710758400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:58 INFO  BlockGenerator:54 - Pushed block input-0-1524710758400
2018-04-25 22:45:58 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 14). 1572 bytes result sent to driver
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 15, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 14) in 319 ms on localhost (executor driver) (2/5)
2018-04-25 22:45:58 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 15)
2018-04-25 22:45:58 INFO  BlockManager:54 - Found block input-0-1524710754200 locally
2018-04-25 22:45:58 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:58 INFO  PythonRunner:54 - Times: total = 90, boot = 90, init = 0, finish = 0
2018-04-25 22:45:58 INFO  PythonRunner:54 - Times: total = 74, boot = -70, init = 144, finish = 0
2018-04-25 22:45:58 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224557_0033_m_000002_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710755000/_temporary/0/task_20180425224557_0033_m_000002
2018-04-25 22:45:58 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224557_0033_m_000002_0: Committed
2018-04-25 22:45:58 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 15). 1615 bytes result sent to driver
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Starting task 3.0 in stage 3.0 (TID 16, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 15) in 143 ms on localhost (executor driver) (3/5)
2018-04-25 22:45:58 INFO  Executor:54 - Running task 3.0 in stage 3.0 (TID 16)
2018-04-25 22:45:58 INFO  BlockManager:54 - Found block input-0-1524710754400 locally
2018-04-25 22:45:58 INFO  MemoryStore:54 - Block input-0-1524710758600 stored as bytes in memory (estimated size 433.0 B, free 413.6 MB)
2018-04-25 22:45:58 INFO  BlockManagerInfo:54 - Added input-0-1524710758600 in memory on 10.0.2.15:45765 (size: 433.0 B, free: 413.8 MB)
2018-04-25 22:45:58 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:58 WARN  BlockManager:66 - Block input-0-1524710758600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:58 INFO  BlockGenerator:54 - Pushed block input-0-1524710758600
2018-04-25 22:45:58 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:58 INFO  PythonRunner:54 - Times: total = 118, boot = 17, init = 101, finish = 0
2018-04-25 22:45:58 INFO  PythonRunner:54 - Times: total = 58, boot = -55, init = 113, finish = 0
2018-04-25 22:45:58 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224557_0033_m_000003_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710755000/_temporary/0/task_20180425224557_0033_m_000003
2018-04-25 22:45:58 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224557_0033_m_000003_0: Committed
2018-04-25 22:45:58 INFO  Executor:54 - Finished task 3.0 in stage 3.0 (TID 16). 1615 bytes result sent to driver
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Starting task 4.0 in stage 3.0 (TID 17, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:45:58 INFO  Executor:54 - Running task 4.0 in stage 3.0 (TID 17)
2018-04-25 22:45:58 INFO  TaskSetManager:54 - Finished task 3.0 in stage 3.0 (TID 16) in 219 ms on localhost (executor driver) (4/5)
2018-04-25 22:45:59 INFO  MemoryStore:54 - Block input-0-1524710758800 stored as bytes in memory (estimated size 402.0 B, free 413.6 MB)
2018-04-25 22:45:59 INFO  BlockManagerInfo:54 - Added input-0-1524710758800 in memory on 10.0.2.15:45765 (size: 402.0 B, free: 413.8 MB)
2018-04-25 22:45:59 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:59 WARN  BlockManager:66 - Block input-0-1524710758800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:59 INFO  BlockGenerator:54 - Pushed block input-0-1524710758800
2018-04-25 22:45:59 INFO  JobScheduler:54 - Added jobs for time 1524710759000 ms
2018-04-25 22:45:59 INFO  BlockManager:54 - Found block input-0-1524710754600 locally
2018-04-25 22:45:59 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:45:59 INFO  PythonRunner:54 - Times: total = 68, boot = -26, init = 94, finish = 0
2018-04-25 22:45:59 INFO  PythonRunner:54 - Times: total = 47, boot = -62, init = 109, finish = 0
2018-04-25 22:45:59 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224557_0033_m_000004_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710755000/_temporary/0/task_20180425224557_0033_m_000004
2018-04-25 22:45:59 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224557_0033_m_000004_0: Committed
2018-04-25 22:45:59 INFO  Executor:54 - Finished task 4.0 in stage 3.0 (TID 17). 1572 bytes result sent to driver
2018-04-25 22:45:59 INFO  TaskSetManager:54 - Finished task 4.0 in stage 3.0 (TID 17) in 201 ms on localhost (executor driver) (5/5)
2018-04-25 22:45:59 INFO  DAGScheduler:54 - ResultStage 3 (runJob at SparkHadoopWriter.scala:78) finished in 1.190 s
2018-04-25 22:45:59 INFO  DAGScheduler:54 - Job 9 finished: runJob at SparkHadoopWriter.scala:78, took 1.215229 s
2018-04-25 22:45:59 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-04-25 22:45:59 INFO  MemoryStore:54 - Block input-0-1524710759000 stored as bytes in memory (estimated size 403.0 B, free 413.6 MB)
2018-04-25 22:45:59 INFO  BlockManagerInfo:54 - Added input-0-1524710759000 in memory on 10.0.2.15:45765 (size: 403.0 B, free: 413.8 MB)
2018-04-25 22:45:59 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:59 WARN  BlockManager:66 - Block input-0-1524710759000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:59 INFO  BlockGenerator:54 - Pushed block input-0-1524710759000
2018-04-25 22:45:59 INFO  SparkHadoopWriter:54 - Job job_20180425224557_0033 committed.
2018-04-25 22:45:59 INFO  JobScheduler:54 - Finished job streaming job 1524710755000 ms.0 from job set of time 1524710755000 ms
2018-04-25 22:45:59 INFO  JobScheduler:54 - Starting job streaming job 1524710755000 ms.1 from job set of time 1524710755000 ms
2018-04-25 22:45:59 INFO  SparkContext:54 - Starting job: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257
2018-04-25 22:45:59 INFO  DAGScheduler:54 - Got job 10 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) with 5 output partitions
2018-04-25 22:45:59 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257)
2018-04-25 22:45:59 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:45:59 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:45:59 INFO  DAGScheduler:54 - Submitting ResultStage 4 (PythonRDD[38] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257), which has no missing parents
2018-04-25 22:45:59 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 7.1 KB, free 413.6 MB)
2018-04-25 22:45:59 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.1 KB, free 413.6 MB)
2018-04-25 22:45:59 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.0.2.15:45765 (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:45:59 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:45:59 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 4 (PythonRDD[38] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:45:59 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 5 tasks
2018-04-25 22:45:59 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 18, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:45:59 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 18)
2018-04-25 22:45:59 INFO  BlockManager:54 - Found block input-0-1524710753800 locally
2018-04-25 22:45:59 INFO  MemoryStore:54 - Block input-0-1524710759200 stored as bytes in memory (estimated size 408.0 B, free 413.6 MB)
2018-04-25 22:45:59 INFO  BlockManagerInfo:54 - Added input-0-1524710759200 in memory on 10.0.2.15:45765 (size: 408.0 B, free: 413.8 MB)
2018-04-25 22:45:59 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:59 WARN  BlockManager:66 - Block input-0-1524710759200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:59 INFO  BlockGenerator:54 - Pushed block input-0-1524710759200
2018-04-25 22:45:59 INFO  PythonRunner:54 - Times: total = 61, boot = -188, init = 249, finish = 0
2018-04-25 22:45:59 INFO  PythonRunner:54 - Times: total = 60, boot = -181, init = 240, finish = 1
2018-04-25 22:45:59 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 18). 1310 bytes result sent to driver
2018-04-25 22:45:59 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 19, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:45:59 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 19)
2018-04-25 22:45:59 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 18) in 107 ms on localhost (executor driver) (1/5)
2018-04-25 22:45:59 INFO  BlockManager:54 - Found block input-0-1524710754000 locally
2018-04-25 22:45:59 INFO  PythonRunner:54 - Times: total = 90, boot = 73, init = 17, finish = 0
2018-04-25 22:45:59 INFO  PythonRunner:54 - Times: total = 56, boot = 25, init = 30, finish = 1
2018-04-25 22:45:59 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 19). 1267 bytes result sent to driver
2018-04-25 22:45:59 INFO  MemoryStore:54 - Block input-0-1524710759400 stored as bytes in memory (estimated size 406.0 B, free 413.6 MB)
2018-04-25 22:45:59 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 20, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:45:59 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 19) in 229 ms on localhost (executor driver) (2/5)
2018-04-25 22:45:59 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 20)
2018-04-25 22:45:59 INFO  BlockManagerInfo:54 - Added input-0-1524710759400 in memory on 10.0.2.15:45765 (size: 406.0 B, free: 413.8 MB)
2018-04-25 22:45:59 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:59 WARN  BlockManager:66 - Block input-0-1524710759400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:59 INFO  BlockGenerator:54 - Pushed block input-0-1524710759400
2018-04-25 22:45:59 INFO  BlockManager:54 - Found block input-0-1524710754200 locally
2018-04-25 22:45:59 INFO  MemoryStore:54 - Block input-0-1524710759600 stored as bytes in memory (estimated size 513.0 B, free 413.6 MB)
2018-04-25 22:45:59 INFO  BlockManagerInfo:54 - Added input-0-1524710759600 in memory on 10.0.2.15:45765 (size: 513.0 B, free: 413.8 MB)
2018-04-25 22:45:59 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:45:59 WARN  BlockManager:66 - Block input-0-1524710759600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:45:59 INFO  BlockGenerator:54 - Pushed block input-0-1524710759600
2018-04-25 22:45:59 INFO  PythonRunner:54 - Times: total = 229, boot = 219, init = 10, finish = 0
2018-04-25 22:46:00 INFO  MemoryStore:54 - Block input-0-1524710759800 stored as bytes in memory (estimated size 69.0 B, free 413.6 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Added input-0-1524710759800 in memory on 10.0.2.15:45765 (size: 69.0 B, free: 413.8 MB)
2018-04-25 22:46:00 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:00 INFO  PythonRunner:54 - Times: total = 54, boot = -3, init = 57, finish = 0
2018-04-25 22:46:00 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 20). 1267 bytes result sent to driver
2018-04-25 22:46:00 WARN  BlockManager:66 - Block input-0-1524710759800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:00 INFO  BlockGenerator:54 - Pushed block input-0-1524710759800
2018-04-25 22:46:00 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 21, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:46:00 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 20) in 376 ms on localhost (executor driver) (3/5)
2018-04-25 22:46:00 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 21)
2018-04-25 22:46:00 INFO  BlockManager:54 - Found block input-0-1524710754400 locally
2018-04-25 22:46:00 INFO  JobScheduler:54 - Added jobs for time 1524710760000 ms
2018-04-25 22:46:00 INFO  PythonRunner:54 - Times: total = 107, boot = -97, init = 204, finish = 0
2018-04-25 22:46:00 INFO  MemoryStore:54 - Block input-0-1524710760000 stored as bytes in memory (estimated size 343.0 B, free 413.6 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Added input-0-1524710760000 in memory on 10.0.2.15:45765 (size: 343.0 B, free: 413.8 MB)
2018-04-25 22:46:00 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:00 WARN  BlockManager:66 - Block input-0-1524710760000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:00 INFO  BlockGenerator:54 - Pushed block input-0-1524710760000
2018-04-25 22:46:00 INFO  PythonRunner:54 - Times: total = 95, boot = 54, init = 25, finish = 16
2018-04-25 22:46:00 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 21). 1310 bytes result sent to driver
2018-04-25 22:46:00 INFO  TaskSetManager:54 - Starting task 4.0 in stage 4.0 (TID 22, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:46:00 INFO  Executor:54 - Running task 4.0 in stage 4.0 (TID 22)
2018-04-25 22:46:00 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 21) in 215 ms on localhost (executor driver) (4/5)
2018-04-25 22:46:00 INFO  BlockManager:54 - Found block input-0-1524710754600 locally
2018-04-25 22:46:00 INFO  PythonRunner:54 - Times: total = 105, boot = 86, init = 0, finish = 19
2018-04-25 22:46:00 INFO  MemoryStore:54 - Block input-0-1524710760200 stored as bytes in memory (estimated size 341.0 B, free 413.6 MB)
2018-04-25 22:46:00 INFO  PythonRunner:54 - Times: total = 107, boot = 92, init = 15, finish = 0
2018-04-25 22:46:00 INFO  Executor:54 - Finished task 4.0 in stage 4.0 (TID 22). 1267 bytes result sent to driver
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Added input-0-1524710760200 in memory on 10.0.2.15:45765 (size: 341.0 B, free: 413.8 MB)
2018-04-25 22:46:00 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:00 WARN  BlockManager:66 - Block input-0-1524710760200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:00 INFO  TaskSetManager:54 - Finished task 4.0 in stage 4.0 (TID 22) in 164 ms on localhost (executor driver) (5/5)
2018-04-25 22:46:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-04-25 22:46:00 INFO  DAGScheduler:54 - ResultStage 4 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) finished in 1.098 s
2018-04-25 22:46:00 INFO  DAGScheduler:54 - Job 10 finished: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257, took 1.110332 s
2018-04-25 22:46:00 INFO  BlockGenerator:54 - Pushed block input-0-1524710760200
2018-04-25 22:46:00 INFO  JobScheduler:54 - Finished job streaming job 1524710755000 ms.1 from job set of time 1524710755000 ms
2018-04-25 22:46:00 INFO  JobScheduler:54 - Total delay: 5.474 s for time 1524710755000 ms (execution: 2.758 s)
2018-04-25 22:46:00 INFO  JobScheduler:54 - Starting job streaming job 1524710756000 ms.0 from job set of time 1524710756000 ms
2018-04-25 22:46:00 INFO  PythonRDD:54 - Removing RDD 20 from persistence list
2018-04-25 22:46:00 INFO  BlockManager:54 - Removing RDD 20
2018-04-25 22:46:00 INFO  BlockRDD:54 - Removing RDD 19 from persistence list
2018-04-25 22:46:00 INFO  BlockManager:54 - Removing RDD 19
2018-04-25 22:46:00 INFO  SocketInputDStream:54 - Removing blocks of RDD BlockRDD[19] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1524710755000 ms
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Removed input-0-1524710752600 on 10.0.2.15:45765 in memory (size: 175.0 B, free: 413.8 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Removed input-0-1524710752800 on 10.0.2.15:45765 in memory (size: 167.0 B, free: 413.8 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Removed input-0-1524710753000 on 10.0.2.15:45765 in memory (size: 426.0 B, free: 413.8 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Removed input-0-1524710753200 on 10.0.2.15:45765 in memory (size: 386.0 B, free: 413.8 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Removed input-0-1524710753400 on 10.0.2.15:45765 in memory (size: 311.0 B, free: 413.8 MB)
2018-04-25 22:46:00 INFO  MemoryStore:54 - Block input-0-1524710760400 stored as bytes in memory (estimated size 406.0 B, free 413.6 MB)
2018-04-25 22:46:00 INFO  ReceivedBlockTracker:54 - Deleting batches: 1524710753000 ms
2018-04-25 22:46:00 INFO  InputInfoTracker:54 - remove old batch metadata: 1524710753000 ms
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Removed input-0-1524710753600 on 10.0.2.15:45765 in memory (size: 401.0 B, free: 413.8 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Added input-0-1524710760400 in memory on 10.0.2.15:45765 (size: 406.0 B, free: 413.8 MB)
2018-04-25 22:46:00 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:00 WARN  BlockManager:66 - Block input-0-1524710760400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:00 INFO  BlockGenerator:54 - Pushed block input-0-1524710760400
2018-04-25 22:46:00 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:00 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:46:00 INFO  DAGScheduler:54 - Got job 11 (runJob at SparkHadoopWriter.scala:78) with 5 output partitions
2018-04-25 22:46:00 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (runJob at SparkHadoopWriter.scala:78)
2018-04-25 22:46:00 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:46:00 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:46:00 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[43] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
2018-04-25 22:46:00 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 75.4 KB, free 413.5 MB)
2018-04-25 22:46:00 INFO  MemoryStore:54 - Block input-0-1524710760600 stored as bytes in memory (estimated size 365.0 B, free 413.5 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Added input-0-1524710760600 in memory on 10.0.2.15:45765 (size: 365.0 B, free: 413.8 MB)
2018-04-25 22:46:00 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:00 WARN  BlockManager:66 - Block input-0-1524710760600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:00 INFO  BlockGenerator:54 - Pushed block input-0-1524710760600
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 109
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 104
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 108
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 114
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 103
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 113
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 107
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 122
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 115
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 124
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 116
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 125
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 105
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 110
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 111
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 119
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 123
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 120
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 121
2018-04-25 22:46:00 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 27.9 KB, free 413.5 MB)
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 10.0.2.15:45765 in memory (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 117
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 101
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 118
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 102
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 112
2018-04-25 22:46:00 INFO  ContextCleaner:54 - Cleaned accumulator 106
2018-04-25 22:46:00 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.2.15:45765 (size: 27.9 KB, free: 413.8 MB)
2018-04-25 22:46:00 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:46:00 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[43] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:46:00 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 5 tasks
2018-04-25 22:46:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 23, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:46:00 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 23)
2018-04-25 22:46:00 INFO  BlockManager:54 - Found block input-0-1524710754800 locally
2018-04-25 22:46:00 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:00 INFO  PythonRunner:54 - Times: total = 47, boot = -504, init = 551, finish = 0
2018-04-25 22:46:00 INFO  PythonRunner:54 - Times: total = 51, boot = -256, init = 307, finish = 0
2018-04-25 22:46:00 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224600_0043_m_000000_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710756000/_temporary/0/task_20180425224600_0043_m_000000
2018-04-25 22:46:00 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224600_0043_m_000000_0: Committed
2018-04-25 22:46:01 INFO  MemoryStore:54 - Block input-0-1524710760800 stored as bytes in memory (estimated size 383.0 B, free 413.5 MB)
2018-04-25 22:46:01 INFO  BlockManagerInfo:54 - Added input-0-1524710760800 in memory on 10.0.2.15:45765 (size: 383.0 B, free: 413.8 MB)
2018-04-25 22:46:01 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:01 WARN  BlockManager:66 - Block input-0-1524710760800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:01 INFO  BlockGenerator:54 - Pushed block input-0-1524710760800
2018-04-25 22:46:01 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 23). 1572 bytes result sent to driver
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Starting task 1.0 in stage 5.0 (TID 24, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:46:01 INFO  Executor:54 - Running task 1.0 in stage 5.0 (TID 24)
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 23) in 187 ms on localhost (executor driver) (1/5)
2018-04-25 22:46:01 INFO  BlockManager:54 - Found block input-0-1524710755000 locally
2018-04-25 22:46:01 INFO  JobScheduler:54 - Added jobs for time 1524710761000 ms
2018-04-25 22:46:01 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 60, boot = 5, init = 55, finish = 0
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 45, boot = -94, init = 138, finish = 1
2018-04-25 22:46:01 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224600_0043_m_000001_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710756000/_temporary/0/task_20180425224600_0043_m_000001
2018-04-25 22:46:01 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224600_0043_m_000001_0: Committed
2018-04-25 22:46:01 INFO  Executor:54 - Finished task 1.0 in stage 5.0 (TID 24). 1572 bytes result sent to driver
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Starting task 2.0 in stage 5.0 (TID 25, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Finished task 1.0 in stage 5.0 (TID 24) in 131 ms on localhost (executor driver) (2/5)
2018-04-25 22:46:01 INFO  Executor:54 - Running task 2.0 in stage 5.0 (TID 25)
2018-04-25 22:46:01 INFO  MemoryStore:54 - Block input-0-1524710761000 stored as bytes in memory (estimated size 407.0 B, free 413.5 MB)
2018-04-25 22:46:01 INFO  BlockManagerInfo:54 - Added input-0-1524710761000 in memory on 10.0.2.15:45765 (size: 407.0 B, free: 413.8 MB)
2018-04-25 22:46:01 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:01 WARN  BlockManager:66 - Block input-0-1524710761000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:01 INFO  BlockGenerator:54 - Pushed block input-0-1524710761000
2018-04-25 22:46:01 INFO  BlockManager:54 - Found block input-0-1524710755200 locally
2018-04-25 22:46:01 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 44, boot = -19, init = 63, finish = 0
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 44, boot = -80, init = 124, finish = 0
2018-04-25 22:46:01 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224600_0043_m_000002_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710756000/_temporary/0/task_20180425224600_0043_m_000002
2018-04-25 22:46:01 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224600_0043_m_000002_0: Committed
2018-04-25 22:46:01 INFO  Executor:54 - Finished task 2.0 in stage 5.0 (TID 25). 1615 bytes result sent to driver
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Starting task 3.0 in stage 5.0 (TID 26, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Finished task 2.0 in stage 5.0 (TID 25) in 156 ms on localhost (executor driver) (3/5)
2018-04-25 22:46:01 INFO  Executor:54 - Running task 3.0 in stage 5.0 (TID 26)
2018-04-25 22:46:01 INFO  BlockManager:54 - Found block input-0-1524710755400 locally
2018-04-25 22:46:01 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:01 INFO  MemoryStore:54 - Block input-0-1524710761200 stored as bytes in memory (estimated size 450.0 B, free 413.5 MB)
2018-04-25 22:46:01 INFO  BlockManagerInfo:54 - Added input-0-1524710761200 in memory on 10.0.2.15:45765 (size: 450.0 B, free: 413.8 MB)
2018-04-25 22:46:01 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:01 WARN  BlockManager:66 - Block input-0-1524710761200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:01 INFO  BlockGenerator:54 - Pushed block input-0-1524710761200
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 70, boot = 10, init = 60, finish = 0
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 56, boot = -25, init = 81, finish = 0
2018-04-25 22:46:01 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224600_0043_m_000003_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710756000/_temporary/0/task_20180425224600_0043_m_000003
2018-04-25 22:46:01 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224600_0043_m_000003_0: Committed
2018-04-25 22:46:01 INFO  Executor:54 - Finished task 3.0 in stage 5.0 (TID 26). 1572 bytes result sent to driver
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Starting task 4.0 in stage 5.0 (TID 27, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Finished task 3.0 in stage 5.0 (TID 26) in 188 ms on localhost (executor driver) (4/5)
2018-04-25 22:46:01 INFO  Executor:54 - Running task 4.0 in stage 5.0 (TID 27)
2018-04-25 22:46:01 INFO  BlockManager:54 - Found block input-0-1524710755600 locally
2018-04-25 22:46:01 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 47, boot = -72, init = 119, finish = 0
2018-04-25 22:46:01 INFO  MemoryStore:54 - Block input-0-1524710761400 stored as bytes in memory (estimated size 371.0 B, free 413.5 MB)
2018-04-25 22:46:01 INFO  BlockManagerInfo:54 - Added input-0-1524710761400 in memory on 10.0.2.15:45765 (size: 371.0 B, free: 413.8 MB)
2018-04-25 22:46:01 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:01 WARN  BlockManager:66 - Block input-0-1524710761400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:01 INFO  BlockGenerator:54 - Pushed block input-0-1524710761400
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 49, boot = -80, init = 129, finish = 0
2018-04-25 22:46:01 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224600_0043_m_000004_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710756000/_temporary/0/task_20180425224600_0043_m_000004
2018-04-25 22:46:01 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224600_0043_m_000004_0: Committed
2018-04-25 22:46:01 INFO  Executor:54 - Finished task 4.0 in stage 5.0 (TID 27). 1572 bytes result sent to driver
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Finished task 4.0 in stage 5.0 (TID 27) in 139 ms on localhost (executor driver) (5/5)
2018-04-25 22:46:01 INFO  DAGScheduler:54 - ResultStage 5 (runJob at SparkHadoopWriter.scala:78) finished in 0.937 s
2018-04-25 22:46:01 INFO  DAGScheduler:54 - Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.967761 s
2018-04-25 22:46:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-04-25 22:46:01 INFO  SparkHadoopWriter:54 - Job job_20180425224600_0043 committed.
2018-04-25 22:46:01 INFO  JobScheduler:54 - Finished job streaming job 1524710756000 ms.0 from job set of time 1524710756000 ms
2018-04-25 22:46:01 INFO  JobScheduler:54 - Starting job streaming job 1524710756000 ms.1 from job set of time 1524710756000 ms
2018-04-25 22:46:01 INFO  SparkContext:54 - Starting job: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257
2018-04-25 22:46:01 INFO  DAGScheduler:54 - Got job 12 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) with 5 output partitions
2018-04-25 22:46:01 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257)
2018-04-25 22:46:01 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:46:01 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:46:01 INFO  DAGScheduler:54 - Submitting ResultStage 6 (PythonRDD[46] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257), which has no missing parents
2018-04-25 22:46:01 INFO  MemoryStore:54 - Block input-0-1524710761600 stored as bytes in memory (estimated size 399.0 B, free 413.5 MB)
2018-04-25 22:46:01 INFO  BlockManagerInfo:54 - Added input-0-1524710761600 in memory on 10.0.2.15:45765 (size: 399.0 B, free: 413.8 MB)
2018-04-25 22:46:01 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:01 WARN  BlockManager:66 - Block input-0-1524710761600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:01 INFO  BlockGenerator:54 - Pushed block input-0-1524710761600
2018-04-25 22:46:01 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 413.5 MB)
2018-04-25 22:46:01 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 10.0.2.15:45765 in memory (size: 27.9 KB, free: 413.8 MB)
2018-04-25 22:46:01 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.1 KB, free 413.6 MB)
2018-04-25 22:46:01 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.2.15:45765 (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:46:01 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:46:01 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 6 (PythonRDD[46] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:46:01 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 5 tasks
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 28, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:46:01 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 28)
2018-04-25 22:46:01 INFO  BlockManager:54 - Found block input-0-1524710754800 locally
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 42, boot = -190, init = 232, finish = 0
2018-04-25 22:46:01 INFO  PythonRunner:54 - Times: total = 47, boot = -188, init = 234, finish = 1
2018-04-25 22:46:01 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 28). 1267 bytes result sent to driver
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Starting task 1.0 in stage 6.0 (TID 29, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:46:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 28) in 72 ms on localhost (executor driver) (1/5)
2018-04-25 22:46:01 INFO  Executor:54 - Running task 1.0 in stage 6.0 (TID 29)
2018-04-25 22:46:01 INFO  BlockManager:54 - Found block input-0-1524710755000 locally
2018-04-25 22:46:02 INFO  MemoryStore:54 - Block input-0-1524710761800 stored as bytes in memory (estimated size 422.0 B, free 413.6 MB)
2018-04-25 22:46:02 INFO  BlockManagerInfo:54 - Added input-0-1524710761800 in memory on 10.0.2.15:45765 (size: 422.0 B, free: 413.8 MB)
2018-04-25 22:46:02 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:02 WARN  BlockManager:66 - Block input-0-1524710761800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:02 INFO  BlockGenerator:54 - Pushed block input-0-1524710761800
2018-04-25 22:46:02 INFO  PythonRunner:54 - Times: total = 140, boot = 140, init = 0, finish = 0
2018-04-25 22:46:02 INFO  PythonRunner:54 - Times: total = 157, boot = 83, init = 74, finish = 0
2018-04-25 22:46:02 INFO  Executor:54 - Finished task 1.0 in stage 6.0 (TID 29). 1267 bytes result sent to driver
2018-04-25 22:46:02 INFO  TaskSetManager:54 - Starting task 2.0 in stage 6.0 (TID 30, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:46:02 INFO  MemoryStore:54 - Block input-0-1524710762000 stored as bytes in memory (estimated size 320.0 B, free 413.6 MB)
2018-04-25 22:46:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 6.0 (TID 29) in 280 ms on localhost (executor driver) (2/5)
2018-04-25 22:46:02 INFO  Executor:54 - Running task 2.0 in stage 6.0 (TID 30)
2018-04-25 22:46:02 INFO  BlockManagerInfo:54 - Added input-0-1524710762000 in memory on 10.0.2.15:45765 (size: 320.0 B, free: 413.8 MB)
2018-04-25 22:46:02 INFO  BlockManager:54 - Found block input-0-1524710755200 locally
2018-04-25 22:46:02 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:02 WARN  BlockManager:66 - Block input-0-1524710762000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:02 INFO  JobScheduler:54 - Added jobs for time 1524710762000 ms
2018-04-25 22:46:02 INFO  BlockGenerator:54 - Pushed block input-0-1524710762000
2018-04-25 22:46:02 INFO  PythonRunner:54 - Times: total = 61, boot = 53, init = 8, finish = 0
2018-04-25 22:46:02 INFO  PythonRunner:54 - Times: total = 112, boot = -75, init = 185, finish = 2
2018-04-25 22:46:02 INFO  Executor:54 - Finished task 2.0 in stage 6.0 (TID 30). 1267 bytes result sent to driver
2018-04-25 22:46:02 INFO  TaskSetManager:54 - Starting task 3.0 in stage 6.0 (TID 31, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:46:02 INFO  TaskSetManager:54 - Finished task 2.0 in stage 6.0 (TID 30) in 188 ms on localhost (executor driver) (3/5)
2018-04-25 22:46:02 INFO  Executor:54 - Running task 3.0 in stage 6.0 (TID 31)
2018-04-25 22:46:02 INFO  MemoryStore:54 - Block input-0-1524710762200 stored as bytes in memory (estimated size 321.0 B, free 413.6 MB)
2018-04-25 22:46:02 INFO  BlockManagerInfo:54 - Added input-0-1524710762200 in memory on 10.0.2.15:45765 (size: 321.0 B, free: 413.8 MB)
2018-04-25 22:46:02 INFO  BlockManager:54 - Found block input-0-1524710755400 locally
2018-04-25 22:46:02 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:02 WARN  BlockManager:66 - Block input-0-1524710762200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:02 INFO  BlockGenerator:54 - Pushed block input-0-1524710762200
2018-04-25 22:46:02 INFO  PythonRunner:54 - Times: total = 67, boot = 66, init = 1, finish = 0
2018-04-25 22:46:02 INFO  PythonRunner:54 - Times: total = 71, boot = 55, init = 15, finish = 1
2018-04-25 22:46:02 INFO  Executor:54 - Finished task 3.0 in stage 6.0 (TID 31). 1267 bytes result sent to driver
2018-04-25 22:46:02 INFO  TaskSetManager:54 - Starting task 4.0 in stage 6.0 (TID 32, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:46:02 INFO  Executor:54 - Running task 4.0 in stage 6.0 (TID 32)
2018-04-25 22:46:02 INFO  TaskSetManager:54 - Finished task 3.0 in stage 6.0 (TID 31) in 124 ms on localhost (executor driver) (4/5)
2018-04-25 22:46:02 INFO  BlockManager:54 - Found block input-0-1524710755600 locally
2018-04-25 22:46:02 INFO  MemoryStore:54 - Block input-0-1524710762400 stored as bytes in memory (estimated size 305.0 B, free 413.6 MB)
2018-04-25 22:46:02 INFO  BlockManagerInfo:54 - Added input-0-1524710762400 in memory on 10.0.2.15:45765 (size: 305.0 B, free: 413.8 MB)
2018-04-25 22:46:02 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:02 WARN  BlockManager:66 - Block input-0-1524710762400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:02 INFO  BlockGenerator:54 - Pushed block input-0-1524710762400
2018-04-25 22:46:02 INFO  PythonRunner:54 - Times: total = 265, boot = 265, init = 0, finish = 0
2018-04-25 22:46:02 INFO  PythonRunner:54 - Times: total = 99, boot = 92, init = 0, finish = 7
2018-04-25 22:46:02 INFO  Executor:54 - Finished task 4.0 in stage 6.0 (TID 32). 1267 bytes result sent to driver
2018-04-25 22:46:02 INFO  TaskSetManager:54 - Finished task 4.0 in stage 6.0 (TID 32) in 296 ms on localhost (executor driver) (5/5)
2018-04-25 22:46:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-04-25 22:46:02 INFO  DAGScheduler:54 - ResultStage 6 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) finished in 0.999 s
2018-04-25 22:46:02 INFO  DAGScheduler:54 - Job 12 finished: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257, took 1.019374 s
2018-04-25 22:46:02 INFO  MemoryStore:54 - Block input-0-1524710762600 stored as bytes in memory (estimated size 372.0 B, free 413.6 MB)
2018-04-25 22:46:02 INFO  BlockManagerInfo:54 - Added input-0-1524710762600 in memory on 10.0.2.15:45765 (size: 372.0 B, free: 413.8 MB)
2018-04-25 22:46:02 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:02 WARN  BlockManager:66 - Block input-0-1524710762600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:02 INFO  BlockGenerator:54 - Pushed block input-0-1524710762600
2018-04-25 22:46:02 INFO  JobScheduler:54 - Finished job streaming job 1524710756000 ms.1 from job set of time 1524710756000 ms
2018-04-25 22:46:02 INFO  JobScheduler:54 - Total delay: 6.834 s for time 1524710756000 ms (execution: 2.353 s)
2018-04-25 22:46:02 INFO  JobScheduler:54 - Starting job streaming job 1524710757000 ms.0 from job set of time 1524710757000 ms
2018-04-25 22:46:02 INFO  PythonRDD:54 - Removing RDD 25 from persistence list
2018-04-25 22:46:02 INFO  BlockManager:54 - Removing RDD 25
2018-04-25 22:46:02 INFO  BlockRDD:54 - Removing RDD 24 from persistence list
2018-04-25 22:46:02 INFO  BlockManager:54 - Removing RDD 24
2018-04-25 22:46:02 INFO  SocketInputDStream:54 - Removing blocks of RDD BlockRDD[24] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1524710756000 ms
2018-04-25 22:46:02 INFO  BlockManagerInfo:54 - Removed input-0-1524710753800 on 10.0.2.15:45765 in memory (size: 395.0 B, free: 413.8 MB)
2018-04-25 22:46:02 INFO  BlockManagerInfo:54 - Removed input-0-1524710754000 on 10.0.2.15:45765 in memory (size: 406.0 B, free: 413.8 MB)
2018-04-25 22:46:03 INFO  MemoryStore:54 - Block input-0-1524710762800 stored as bytes in memory (estimated size 341.0 B, free 413.6 MB)
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Added input-0-1524710762800 in memory on 10.0.2.15:45765 (size: 341.0 B, free: 413.8 MB)
2018-04-25 22:46:03 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:03 WARN  BlockManager:66 - Block input-0-1524710762800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:03 INFO  BlockGenerator:54 - Pushed block input-0-1524710762800
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Removed input-0-1524710754200 on 10.0.2.15:45765 in memory (size: 406.0 B, free: 413.8 MB)
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Removed input-0-1524710754400 on 10.0.2.15:45765 in memory (size: 403.0 B, free: 413.8 MB)
2018-04-25 22:46:03 INFO  ReceivedBlockTracker:54 - Deleting batches: 1524710754000 ms
2018-04-25 22:46:03 INFO  InputInfoTracker:54 - remove old batch metadata: 1524710754000 ms
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Removed input-0-1524710754600 on 10.0.2.15:45765 in memory (size: 411.0 B, free: 413.8 MB)
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 172
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 169
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 155
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 161
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 175
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 163
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 162
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 174
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 158
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 173
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 156
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 167
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 157
2018-04-25 22:46:03 INFO  JobScheduler:54 - Added jobs for time 1524710763000 ms
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 10.0.2.15:45765 in memory (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 171
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 160
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 154
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 159
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 166
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 165
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 153
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 170
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 152
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 151
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 164
2018-04-25 22:46:03 INFO  ContextCleaner:54 - Cleaned accumulator 168
2018-04-25 22:46:03 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:03 INFO  MemoryStore:54 - Block input-0-1524710763000 stored as bytes in memory (estimated size 368.0 B, free 413.6 MB)
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Added input-0-1524710763000 in memory on 10.0.2.15:45765 (size: 368.0 B, free: 413.8 MB)
2018-04-25 22:46:03 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:03 WARN  BlockManager:66 - Block input-0-1524710763000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:03 INFO  BlockGenerator:54 - Pushed block input-0-1524710763000
2018-04-25 22:46:03 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:46:03 INFO  DAGScheduler:54 - Got job 13 (runJob at SparkHadoopWriter.scala:78) with 5 output partitions
2018-04-25 22:46:03 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (runJob at SparkHadoopWriter.scala:78)
2018-04-25 22:46:03 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:46:03 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:46:03 INFO  DAGScheduler:54 - Submitting ResultStage 7 (MapPartitionsRDD[52] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
2018-04-25 22:46:03 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 75.4 KB, free 413.5 MB)
2018-04-25 22:46:03 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 27.9 KB, free 413.5 MB)
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.2.15:45765 (size: 27.9 KB, free: 413.8 MB)
2018-04-25 22:46:03 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:46:03 INFO  MemoryStore:54 - Block input-0-1524710763200 stored as bytes in memory (estimated size 357.0 B, free 413.5 MB)
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Added input-0-1524710763200 in memory on 10.0.2.15:45765 (size: 357.0 B, free: 413.8 MB)
2018-04-25 22:46:03 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:03 WARN  BlockManager:66 - Block input-0-1524710763200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:03 INFO  BlockGenerator:54 - Pushed block input-0-1524710763200
2018-04-25 22:46:03 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 7 (MapPartitionsRDD[52] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:46:03 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 5 tasks
2018-04-25 22:46:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 33, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:46:03 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 33)
2018-04-25 22:46:03 INFO  BlockManager:54 - Found block input-0-1524710755800 locally
2018-04-25 22:46:03 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:03 INFO  PythonRunner:54 - Times: total = 57, boot = -446, init = 503, finish = 0
2018-04-25 22:46:03 INFO  PythonRunner:54 - Times: total = 57, boot = -461, init = 518, finish = 0
2018-04-25 22:46:03 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224603_0052_m_000000_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710757000/_temporary/0/task_20180425224603_0052_m_000000
2018-04-25 22:46:03 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224603_0052_m_000000_0: Committed
2018-04-25 22:46:03 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 33). 1572 bytes result sent to driver
2018-04-25 22:46:03 INFO  TaskSetManager:54 - Starting task 1.0 in stage 7.0 (TID 34, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:46:03 INFO  Executor:54 - Running task 1.0 in stage 7.0 (TID 34)
2018-04-25 22:46:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 33) in 121 ms on localhost (executor driver) (1/5)
2018-04-25 22:46:03 INFO  BlockManager:54 - Found block input-0-1524710756000 locally
2018-04-25 22:46:03 INFO  MemoryStore:54 - Block input-0-1524710763400 stored as bytes in memory (estimated size 410.0 B, free 413.5 MB)
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Added input-0-1524710763400 in memory on 10.0.2.15:45765 (size: 410.0 B, free: 413.8 MB)
2018-04-25 22:46:03 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:03 WARN  BlockManager:66 - Block input-0-1524710763400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:03 INFO  BlockGenerator:54 - Pushed block input-0-1524710763400
2018-04-25 22:46:03 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:03 INFO  PythonRunner:54 - Times: total = 50, boot = -23, init = 73, finish = 0
2018-04-25 22:46:03 INFO  PythonRunner:54 - Times: total = 54, boot = -28, init = 82, finish = 0
2018-04-25 22:46:03 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224603_0052_m_000001_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710757000/_temporary/0/task_20180425224603_0052_m_000001
2018-04-25 22:46:03 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224603_0052_m_000001_0: Committed
2018-04-25 22:46:03 INFO  Executor:54 - Finished task 1.0 in stage 7.0 (TID 34). 1615 bytes result sent to driver
2018-04-25 22:46:03 INFO  TaskSetManager:54 - Starting task 2.0 in stage 7.0 (TID 35, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:46:03 INFO  TaskSetManager:54 - Finished task 1.0 in stage 7.0 (TID 34) in 144 ms on localhost (executor driver) (2/5)
2018-04-25 22:46:03 INFO  Executor:54 - Running task 2.0 in stage 7.0 (TID 35)
2018-04-25 22:46:03 INFO  BlockManager:54 - Found block input-0-1524710756200 locally
2018-04-25 22:46:03 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:03 INFO  PythonRunner:54 - Times: total = 45, boot = 0, init = 44, finish = 1
2018-04-25 22:46:03 INFO  PythonRunner:54 - Times: total = 54, boot = -25, init = 79, finish = 0
2018-04-25 22:46:03 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224603_0052_m_000002_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710757000/_temporary/0/task_20180425224603_0052_m_000002
2018-04-25 22:46:03 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224603_0052_m_000002_0: Committed
2018-04-25 22:46:03 INFO  Executor:54 - Finished task 2.0 in stage 7.0 (TID 35). 1572 bytes result sent to driver
2018-04-25 22:46:03 INFO  MemoryStore:54 - Block input-0-1524710763600 stored as bytes in memory (estimated size 383.0 B, free 413.5 MB)
2018-04-25 22:46:03 INFO  TaskSetManager:54 - Starting task 3.0 in stage 7.0 (TID 36, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:46:03 INFO  Executor:54 - Running task 3.0 in stage 7.0 (TID 36)
2018-04-25 22:46:03 INFO  TaskSetManager:54 - Finished task 2.0 in stage 7.0 (TID 35) in 137 ms on localhost (executor driver) (3/5)
2018-04-25 22:46:03 INFO  BlockManagerInfo:54 - Added input-0-1524710763600 in memory on 10.0.2.15:45765 (size: 383.0 B, free: 413.8 MB)
2018-04-25 22:46:03 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:03 WARN  BlockManager:66 - Block input-0-1524710763600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:03 INFO  BlockGenerator:54 - Pushed block input-0-1524710763600
2018-04-25 22:46:03 INFO  BlockManager:54 - Found block input-0-1524710756400 locally
2018-04-25 22:46:03 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:03 INFO  PythonRunner:54 - Times: total = 83, boot = -8, init = 91, finish = 0
2018-04-25 22:46:03 INFO  PythonRunner:54 - Times: total = 51, boot = -41, init = 92, finish = 0
2018-04-25 22:46:03 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224603_0052_m_000003_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710757000/_temporary/0/task_20180425224603_0052_m_000003
2018-04-25 22:46:03 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224603_0052_m_000003_0: Committed
2018-04-25 22:46:03 INFO  Executor:54 - Finished task 3.0 in stage 7.0 (TID 36). 1572 bytes result sent to driver
2018-04-25 22:46:03 INFO  TaskSetManager:54 - Starting task 4.0 in stage 7.0 (TID 37, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:46:04 INFO  MemoryStore:54 - Block input-0-1524710763800 stored as bytes in memory (estimated size 360.0 B, free 413.5 MB)
2018-04-25 22:46:04 INFO  Executor:54 - Running task 4.0 in stage 7.0 (TID 37)
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Finished task 3.0 in stage 7.0 (TID 36) in 204 ms on localhost (executor driver) (4/5)
2018-04-25 22:46:04 INFO  BlockManagerInfo:54 - Added input-0-1524710763800 in memory on 10.0.2.15:45765 (size: 360.0 B, free: 413.8 MB)
2018-04-25 22:46:04 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:04 WARN  BlockManager:66 - Block input-0-1524710763800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:04 INFO  BlockGenerator:54 - Pushed block input-0-1524710763800
2018-04-25 22:46:04 INFO  JobScheduler:54 - Added jobs for time 1524710764000 ms
2018-04-25 22:46:04 INFO  BlockManager:54 - Found block input-0-1524710756600 locally
2018-04-25 22:46:04 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 61, boot = -1, init = 62, finish = 0
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 54, boot = -20, init = 73, finish = 1
2018-04-25 22:46:04 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224603_0052_m_000004_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710757000/_temporary/0/task_20180425224603_0052_m_000004
2018-04-25 22:46:04 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224603_0052_m_000004_0: Committed
2018-04-25 22:46:04 INFO  Executor:54 - Finished task 4.0 in stage 7.0 (TID 37). 1572 bytes result sent to driver
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Finished task 4.0 in stage 7.0 (TID 37) in 160 ms on localhost (executor driver) (5/5)
2018-04-25 22:46:04 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-04-25 22:46:04 INFO  DAGScheduler:54 - ResultStage 7 (runJob at SparkHadoopWriter.scala:78) finished in 0.826 s
2018-04-25 22:46:04 INFO  DAGScheduler:54 - Job 13 finished: runJob at SparkHadoopWriter.scala:78, took 0.904441 s
2018-04-25 22:46:04 INFO  MemoryStore:54 - Block input-0-1524710764000 stored as bytes in memory (estimated size 411.0 B, free 413.5 MB)
2018-04-25 22:46:04 INFO  BlockManagerInfo:54 - Added input-0-1524710764000 in memory on 10.0.2.15:45765 (size: 411.0 B, free: 413.8 MB)
2018-04-25 22:46:04 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:04 WARN  BlockManager:66 - Block input-0-1524710764000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:04 INFO  BlockGenerator:54 - Pushed block input-0-1524710764000
2018-04-25 22:46:04 INFO  SparkHadoopWriter:54 - Job job_20180425224603_0052 committed.
2018-04-25 22:46:04 INFO  JobScheduler:54 - Finished job streaming job 1524710757000 ms.0 from job set of time 1524710757000 ms
2018-04-25 22:46:04 INFO  JobScheduler:54 - Starting job streaming job 1524710757000 ms.1 from job set of time 1524710757000 ms
2018-04-25 22:46:04 INFO  SparkContext:54 - Starting job: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257
2018-04-25 22:46:04 INFO  DAGScheduler:54 - Got job 14 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) with 5 output partitions
2018-04-25 22:46:04 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257)
2018-04-25 22:46:04 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:46:04 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:46:04 INFO  DAGScheduler:54 - Submitting ResultStage 8 (PythonRDD[56] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257), which has no missing parents
2018-04-25 22:46:04 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 413.5 MB)
2018-04-25 22:46:04 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.1 KB, free 413.5 MB)
2018-04-25 22:46:04 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.2.15:45765 (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:46:04 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:46:04 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 8 (PythonRDD[56] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:46:04 INFO  TaskSchedulerImpl:54 - Adding task set 8.0 with 5 tasks
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 38, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:46:04 INFO  Executor:54 - Running task 0.0 in stage 8.0 (TID 38)
2018-04-25 22:46:04 INFO  BlockManager:54 - Found block input-0-1524710755800 locally
2018-04-25 22:46:04 INFO  MemoryStore:54 - Block input-0-1524710764200 stored as bytes in memory (estimated size 406.0 B, free 413.5 MB)
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 52, boot = -155, init = 206, finish = 1
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 62, boot = -166, init = 223, finish = 5
2018-04-25 22:46:04 INFO  Executor:54 - Finished task 0.0 in stage 8.0 (TID 38). 1267 bytes result sent to driver
2018-04-25 22:46:04 INFO  BlockManagerInfo:54 - Added input-0-1524710764200 in memory on 10.0.2.15:45765 (size: 406.0 B, free: 413.8 MB)
2018-04-25 22:46:04 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Starting task 1.0 in stage 8.0 (TID 39, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 38) in 118 ms on localhost (executor driver) (1/5)
2018-04-25 22:46:04 INFO  Executor:54 - Running task 1.0 in stage 8.0 (TID 39)
2018-04-25 22:46:04 WARN  BlockManager:66 - Block input-0-1524710764200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:04 INFO  BlockManager:54 - Found block input-0-1524710756000 locally
2018-04-25 22:46:04 INFO  BlockGenerator:54 - Pushed block input-0-1524710764200
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 64, boot = 39, init = 25, finish = 0
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 66, boot = 53, init = 1, finish = 12
2018-04-25 22:46:04 INFO  Executor:54 - Finished task 1.0 in stage 8.0 (TID 39). 1267 bytes result sent to driver
2018-04-25 22:46:04 INFO  MemoryStore:54 - Block input-0-1524710764400 stored as bytes in memory (estimated size 404.0 B, free 413.5 MB)
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Starting task 2.0 in stage 8.0 (TID 40, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:46:04 INFO  Executor:54 - Running task 2.0 in stage 8.0 (TID 40)
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Finished task 1.0 in stage 8.0 (TID 39) in 182 ms on localhost (executor driver) (2/5)
2018-04-25 22:46:04 INFO  BlockManager:54 - Found block input-0-1524710756200 locally
2018-04-25 22:46:04 INFO  BlockManagerInfo:54 - Added input-0-1524710764400 in memory on 10.0.2.15:45765 (size: 404.0 B, free: 413.8 MB)
2018-04-25 22:46:04 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:04 WARN  BlockManager:66 - Block input-0-1524710764400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:04 INFO  BlockGenerator:54 - Pushed block input-0-1524710764400
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 88, boot = 79, init = 8, finish = 1
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 95, boot = 63, init = 0, finish = 32
2018-04-25 22:46:04 INFO  Executor:54 - Finished task 2.0 in stage 8.0 (TID 40). 1267 bytes result sent to driver
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Starting task 3.0 in stage 8.0 (TID 41, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:46:04 INFO  Executor:54 - Running task 3.0 in stage 8.0 (TID 41)
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Finished task 2.0 in stage 8.0 (TID 40) in 151 ms on localhost (executor driver) (3/5)
2018-04-25 22:46:04 INFO  MemoryStore:54 - Block input-0-1524710764600 stored as bytes in memory (estimated size 360.0 B, free 413.5 MB)
2018-04-25 22:46:04 INFO  BlockManagerInfo:54 - Added input-0-1524710764600 in memory on 10.0.2.15:45765 (size: 360.0 B, free: 413.8 MB)
2018-04-25 22:46:04 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:04 WARN  BlockManager:66 - Block input-0-1524710764600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:04 INFO  BlockManager:54 - Found block input-0-1524710756400 locally
2018-04-25 22:46:04 INFO  BlockGenerator:54 - Pushed block input-0-1524710764600
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 55, boot = 54, init = 1, finish = 0
2018-04-25 22:46:04 INFO  PythonRunner:54 - Times: total = 120, boot = 108, init = 0, finish = 12
2018-04-25 22:46:04 INFO  Executor:54 - Finished task 3.0 in stage 8.0 (TID 41). 1267 bytes result sent to driver
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Starting task 4.0 in stage 8.0 (TID 42, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:46:04 INFO  TaskSetManager:54 - Finished task 3.0 in stage 8.0 (TID 41) in 204 ms on localhost (executor driver) (4/5)
2018-04-25 22:46:04 INFO  Executor:54 - Running task 4.0 in stage 8.0 (TID 42)
2018-04-25 22:46:04 INFO  BlockManager:54 - Found block input-0-1524710756600 locally
2018-04-25 22:46:05 INFO  MemoryStore:54 - Block input-0-1524710764800 stored as bytes in memory (estimated size 289.0 B, free 413.5 MB)
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Added input-0-1524710764800 in memory on 10.0.2.15:45765 (size: 289.0 B, free: 413.8 MB)
2018-04-25 22:46:05 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:05 WARN  BlockManager:66 - Block input-0-1524710764800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:05 INFO  BlockGenerator:54 - Pushed block input-0-1524710764800
2018-04-25 22:46:05 INFO  JobScheduler:54 - Added jobs for time 1524710765000 ms
2018-04-25 22:46:05 INFO  PythonRunner:54 - Times: total = 107, boot = 106, init = 0, finish = 1
2018-04-25 22:46:05 INFO  PythonRunner:54 - Times: total = 156, boot = 63, init = 32, finish = 61
2018-04-25 22:46:05 INFO  Executor:54 - Finished task 4.0 in stage 8.0 (TID 42). 1267 bytes result sent to driver
2018-04-25 22:46:05 INFO  TaskSetManager:54 - Finished task 4.0 in stage 8.0 (TID 42) in 212 ms on localhost (executor driver) (5/5)
2018-04-25 22:46:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-04-25 22:46:05 INFO  DAGScheduler:54 - ResultStage 8 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) finished in 0.888 s
2018-04-25 22:46:05 INFO  DAGScheduler:54 - Job 14 finished: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257, took 0.906209 s
2018-04-25 22:46:05 INFO  MemoryStore:54 - Block input-0-1524710765000 stored as bytes in memory (estimated size 357.0 B, free 413.5 MB)
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 204
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 203
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 224
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 221
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 222
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 214
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 202
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 201
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 220
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 213
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 211
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 205
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 210
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 219
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 208
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 206
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 207
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 225
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Added input-0-1524710765000 in memory on 10.0.2.15:45765 (size: 357.0 B, free: 413.8 MB)
2018-04-25 22:46:05 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:05 WARN  BlockManager:66 - Block input-0-1524710765000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:05 INFO  BlockGenerator:54 - Pushed block input-0-1524710765000
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 217
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 215
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 209
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 223
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 212
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 216
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 10.0.2.15:45765 in memory (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 218
2018-04-25 22:46:05 INFO  JobScheduler:54 - Finished job streaming job 1524710757000 ms.1 from job set of time 1524710757000 ms
2018-04-25 22:46:05 INFO  JobScheduler:54 - Total delay: 8.361 s for time 1524710757000 ms (execution: 2.526 s)
2018-04-25 22:46:05 INFO  JobScheduler:54 - Starting job streaming job 1524710758000 ms.0 from job set of time 1524710758000 ms
2018-04-25 22:46:05 INFO  PythonRDD:54 - Removing RDD 27 from persistence list
2018-04-25 22:46:05 INFO  BlockManager:54 - Removing RDD 27
2018-04-25 22:46:05 INFO  BlockRDD:54 - Removing RDD 26 from persistence list
2018-04-25 22:46:05 INFO  BlockManager:54 - Removing RDD 26
2018-04-25 22:46:05 INFO  SocketInputDStream:54 - Removing blocks of RDD BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1524710757000 ms
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Removed input-0-1524710754800 on 10.0.2.15:45765 in memory (size: 405.0 B, free: 413.8 MB)
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Removed input-0-1524710755000 on 10.0.2.15:45765 in memory (size: 399.0 B, free: 413.8 MB)
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Removed input-0-1524710755200 on 10.0.2.15:45765 in memory (size: 407.0 B, free: 413.8 MB)
2018-04-25 22:46:05 INFO  MemoryStore:54 - Block input-0-1524710765200 stored as bytes in memory (estimated size 316.0 B, free 413.5 MB)
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Added input-0-1524710765200 in memory on 10.0.2.15:45765 (size: 316.0 B, free: 413.8 MB)
2018-04-25 22:46:05 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:05 WARN  BlockManager:66 - Block input-0-1524710765200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:05 INFO  BlockGenerator:54 - Pushed block input-0-1524710765200
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Removed input-0-1524710755400 on 10.0.2.15:45765 in memory (size: 402.0 B, free: 413.8 MB)
2018-04-25 22:46:05 INFO  ReceivedBlockTracker:54 - Deleting batches: 1524710755000 ms
2018-04-25 22:46:05 INFO  InputInfoTracker:54 - remove old batch metadata: 1524710755000 ms
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Removed input-0-1524710755600 on 10.0.2.15:45765 in memory (size: 408.0 B, free: 413.8 MB)
2018-04-25 22:46:05 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:05 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:46:05 INFO  DAGScheduler:54 - Got job 15 (runJob at SparkHadoopWriter.scala:78) with 5 output partitions
2018-04-25 22:46:05 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (runJob at SparkHadoopWriter.scala:78)
2018-04-25 22:46:05 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:46:05 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:46:05 INFO  DAGScheduler:54 - Submitting ResultStage 9 (MapPartitionsRDD[61] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
2018-04-25 22:46:05 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 75.4 KB, free 413.4 MB)
2018-04-25 22:46:05 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 27.9 KB, free 413.4 MB)
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.2.15:45765 (size: 27.9 KB, free: 413.8 MB)
2018-04-25 22:46:05 INFO  MemoryStore:54 - Block input-0-1524710765400 stored as bytes in memory (estimated size 420.0 B, free 413.4 MB)
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Added input-0-1524710765400 in memory on 10.0.2.15:45765 (size: 420.0 B, free: 413.8 MB)
2018-04-25 22:46:05 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:05 WARN  BlockManager:66 - Block input-0-1524710765400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:05 INFO  BlockGenerator:54 - Pushed block input-0-1524710765400
2018-04-25 22:46:05 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:46:05 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 9 (MapPartitionsRDD[61] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:46:05 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 5 tasks
2018-04-25 22:46:05 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 43, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:46:05 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 43)
2018-04-25 22:46:05 INFO  BlockManager:54 - Found block input-0-1524710756800 locally
2018-04-25 22:46:05 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:05 INFO  PythonRunner:54 - Times: total = 61, boot = 60, init = 0, finish = 1
2018-04-25 22:46:05 INFO  PythonRunner:54 - Times: total = 54, boot = -234, init = 288, finish = 0
2018-04-25 22:46:05 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224605_0061_m_000000_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710758000/_temporary/0/task_20180425224605_0061_m_000000
2018-04-25 22:46:05 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224605_0061_m_000000_0: Committed
2018-04-25 22:46:05 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 43). 1572 bytes result sent to driver
2018-04-25 22:46:05 INFO  TaskSetManager:54 - Starting task 1.0 in stage 9.0 (TID 44, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:46:05 INFO  Executor:54 - Running task 1.0 in stage 9.0 (TID 44)
2018-04-25 22:46:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 43) in 132 ms on localhost (executor driver) (1/5)
2018-04-25 22:46:05 INFO  MemoryStore:54 - Block input-0-1524710765600 stored as bytes in memory (estimated size 336.0 B, free 413.4 MB)
2018-04-25 22:46:05 INFO  BlockManagerInfo:54 - Added input-0-1524710765600 in memory on 10.0.2.15:45765 (size: 336.0 B, free: 413.8 MB)
2018-04-25 22:46:05 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:05 WARN  BlockManager:66 - Block input-0-1524710765600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:05 INFO  BlockGenerator:54 - Pushed block input-0-1524710765600
2018-04-25 22:46:05 INFO  BlockManager:54 - Found block input-0-1524710757000 locally
2018-04-25 22:46:05 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:05 INFO  PythonRunner:54 - Times: total = 51, boot = 16, init = 34, finish = 1
2018-04-25 22:46:05 INFO  PythonRunner:54 - Times: total = 47, boot = -82, init = 129, finish = 0
2018-04-25 22:46:05 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224605_0061_m_000001_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710758000/_temporary/0/task_20180425224605_0061_m_000001
2018-04-25 22:46:05 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224605_0061_m_000001_0: Committed
2018-04-25 22:46:05 INFO  Executor:54 - Finished task 1.0 in stage 9.0 (TID 44). 1615 bytes result sent to driver
2018-04-25 22:46:05 INFO  TaskSetManager:54 - Starting task 2.0 in stage 9.0 (TID 45, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:46:05 INFO  TaskSetManager:54 - Finished task 1.0 in stage 9.0 (TID 44) in 142 ms on localhost (executor driver) (2/5)
2018-04-25 22:46:05 INFO  Executor:54 - Running task 2.0 in stage 9.0 (TID 45)
2018-04-25 22:46:05 INFO  BlockManager:54 - Found block input-0-1524710757200 locally
2018-04-25 22:46:05 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:05 INFO  PythonRunner:54 - Times: total = 69, boot = 8, init = 61, finish = 0
2018-04-25 22:46:06 INFO  PythonRunner:54 - Times: total = 52, boot = -10, init = 62, finish = 0
2018-04-25 22:46:06 INFO  MemoryStore:54 - Block input-0-1524710765800 stored as bytes in memory (estimated size 507.0 B, free 413.4 MB)
2018-04-25 22:46:06 INFO  BlockManagerInfo:54 - Added input-0-1524710765800 in memory on 10.0.2.15:45765 (size: 507.0 B, free: 413.8 MB)
2018-04-25 22:46:06 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:06 WARN  BlockManager:66 - Block input-0-1524710765800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:06 INFO  BlockGenerator:54 - Pushed block input-0-1524710765800
2018-04-25 22:46:06 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224605_0061_m_000002_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710758000/_temporary/0/task_20180425224605_0061_m_000002
2018-04-25 22:46:06 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224605_0061_m_000002_0: Committed
2018-04-25 22:46:06 INFO  Executor:54 - Finished task 2.0 in stage 9.0 (TID 45). 1572 bytes result sent to driver
2018-04-25 22:46:06 INFO  TaskSetManager:54 - Starting task 3.0 in stage 9.0 (TID 46, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:46:06 INFO  Executor:54 - Running task 3.0 in stage 9.0 (TID 46)
2018-04-25 22:46:06 INFO  TaskSetManager:54 - Finished task 2.0 in stage 9.0 (TID 45) in 156 ms on localhost (executor driver) (3/5)
2018-04-25 22:46:06 INFO  BlockManager:54 - Found block input-0-1524710757400 locally
2018-04-25 22:46:06 INFO  JobScheduler:54 - Added jobs for time 1524710766000 ms
2018-04-25 22:46:06 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:06 INFO  PythonRunner:54 - Times: total = 47, boot = 12, init = 34, finish = 1
2018-04-25 22:46:06 INFO  PythonRunner:54 - Times: total = 46, boot = 2, init = 42, finish = 2
2018-04-25 22:46:06 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224605_0061_m_000003_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710758000/_temporary/0/task_20180425224605_0061_m_000003
2018-04-25 22:46:06 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224605_0061_m_000003_0: Committed
2018-04-25 22:46:06 INFO  Executor:54 - Finished task 3.0 in stage 9.0 (TID 46). 1572 bytes result sent to driver
2018-04-25 22:46:06 INFO  TaskSetManager:54 - Starting task 4.0 in stage 9.0 (TID 47, localhost, executor driver, partition 4, ANY, 7772 bytes)
2018-04-25 22:46:06 INFO  TaskSetManager:54 - Finished task 3.0 in stage 9.0 (TID 46) in 140 ms on localhost (executor driver) (4/5)
2018-04-25 22:46:06 INFO  Executor:54 - Running task 4.0 in stage 9.0 (TID 47)
2018-04-25 22:46:06 INFO  MemoryStore:54 - Block input-0-1524710766000 stored as bytes in memory (estimated size 422.0 B, free 413.4 MB)
2018-04-25 22:46:06 INFO  BlockManagerInfo:54 - Added input-0-1524710766000 in memory on 10.0.2.15:45765 (size: 422.0 B, free: 413.8 MB)
2018-04-25 22:46:06 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:06 WARN  BlockManager:66 - Block input-0-1524710766000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:06 INFO  BlockGenerator:54 - Pushed block input-0-1524710766000
2018-04-25 22:46:06 INFO  BlockManager:54 - Found block input-0-1524710757600 locally
2018-04-25 22:46:06 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:06 INFO  PythonRunner:54 - Times: total = 49, boot = 14, init = 35, finish = 0
2018-04-25 22:46:06 INFO  PythonRunner:54 - Times: total = 58, boot = -2, init = 60, finish = 0
2018-04-25 22:46:06 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224605_0061_m_000004_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710758000/_temporary/0/task_20180425224605_0061_m_000004
2018-04-25 22:46:06 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224605_0061_m_000004_0: Committed
2018-04-25 22:46:06 INFO  Executor:54 - Finished task 4.0 in stage 9.0 (TID 47). 1615 bytes result sent to driver
2018-04-25 22:46:06 INFO  MemoryStore:54 - Block input-0-1524710766200 stored as bytes in memory (estimated size 291.0 B, free 413.4 MB)
2018-04-25 22:46:06 INFO  TaskSetManager:54 - Finished task 4.0 in stage 9.0 (TID 47) in 291 ms on localhost (executor driver) (5/5)
2018-04-25 22:46:06 INFO  DAGScheduler:54 - ResultStage 9 (runJob at SparkHadoopWriter.scala:78) finished in 0.937 s
2018-04-25 22:46:06 INFO  DAGScheduler:54 - Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.967618 s
2018-04-25 22:46:06 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-04-25 22:46:06 INFO  BlockManagerInfo:54 - Added input-0-1524710766200 in memory on 10.0.2.15:45765 (size: 291.0 B, free: 413.8 MB)
2018-04-25 22:46:06 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:06 WARN  BlockManager:66 - Block input-0-1524710766200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:06 INFO  BlockGenerator:54 - Pushed block input-0-1524710766200
2018-04-25 22:46:06 INFO  SparkHadoopWriter:54 - Job job_20180425224605_0061 committed.
2018-04-25 22:46:06 INFO  JobScheduler:54 - Finished job streaming job 1524710758000 ms.0 from job set of time 1524710758000 ms
2018-04-25 22:46:06 INFO  JobScheduler:54 - Starting job streaming job 1524710758000 ms.1 from job set of time 1524710758000 ms
2018-04-25 22:46:06 INFO  MemoryStore:54 - Block input-0-1524710766400 stored as bytes in memory (estimated size 497.0 B, free 413.4 MB)
2018-04-25 22:46:06 INFO  BlockManagerInfo:54 - Added input-0-1524710766400 in memory on 10.0.2.15:45765 (size: 497.0 B, free: 413.8 MB)
2018-04-25 22:46:06 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:06 WARN  BlockManager:66 - Block input-0-1524710766400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:06 INFO  BlockGenerator:54 - Pushed block input-0-1524710766400
2018-04-25 22:46:06 INFO  SparkContext:54 - Starting job: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257
2018-04-25 22:46:06 INFO  DAGScheduler:54 - Got job 16 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) with 5 output partitions
2018-04-25 22:46:06 INFO  DAGScheduler:54 - Final stage: ResultStage 10 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257)
2018-04-25 22:46:06 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:46:06 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:46:06 INFO  DAGScheduler:54 - Submitting ResultStage 10 (PythonRDD[64] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257), which has no missing parents
2018-04-25 22:46:06 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 413.4 MB)
2018-04-25 22:46:06 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.1 KB, free 413.4 MB)
2018-04-25 22:46:06 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 10.0.2.15:45765 (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:46:06 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:46:06 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 10 (PythonRDD[64] at call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:46:06 INFO  TaskSchedulerImpl:54 - Adding task set 10.0 with 5 tasks
2018-04-25 22:46:06 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 48, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:46:06 INFO  Executor:54 - Running task 0.0 in stage 10.0 (TID 48)
2018-04-25 22:46:06 INFO  BlockManager:54 - Found block input-0-1524710756800 locally
2018-04-25 22:46:06 INFO  MemoryStore:54 - Block input-0-1524710766600 stored as bytes in memory (estimated size 375.0 B, free 413.4 MB)
2018-04-25 22:46:06 INFO  BlockManagerInfo:54 - Added input-0-1524710766600 in memory on 10.0.2.15:45765 (size: 375.0 B, free: 413.8 MB)
2018-04-25 22:46:06 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:06 WARN  BlockManager:66 - Block input-0-1524710766600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:06 INFO  BlockGenerator:54 - Pushed block input-0-1524710766600
2018-04-25 22:46:06 INFO  PythonRunner:54 - Times: total = 197, boot = 197, init = 0, finish = 0
2018-04-25 22:46:06 INFO  PythonRunner:54 - Times: total = 191, boot = -299, init = 489, finish = 1
2018-04-25 22:46:06 INFO  Executor:54 - Finished task 0.0 in stage 10.0 (TID 48). 1267 bytes result sent to driver
2018-04-25 22:46:06 INFO  TaskSetManager:54 - Starting task 1.0 in stage 10.0 (TID 49, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:46:06 INFO  Executor:54 - Running task 1.0 in stage 10.0 (TID 49)
2018-04-25 22:46:06 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 48) in 259 ms on localhost (executor driver) (1/5)
2018-04-25 22:46:07 INFO  MemoryStore:54 - Block input-0-1524710766800 stored as bytes in memory (estimated size 359.0 B, free 413.4 MB)
2018-04-25 22:46:07 INFO  BlockManagerInfo:54 - Added input-0-1524710766800 in memory on 10.0.2.15:45765 (size: 359.0 B, free: 413.8 MB)
2018-04-25 22:46:07 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:07 WARN  BlockManager:66 - Block input-0-1524710766800 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:07 INFO  BlockGenerator:54 - Pushed block input-0-1524710766800
2018-04-25 22:46:07 INFO  JobScheduler:54 - Added jobs for time 1524710767000 ms
2018-04-25 22:46:07 INFO  BlockManager:54 - Found block input-0-1524710757000 locally
2018-04-25 22:46:07 INFO  MemoryStore:54 - Block input-0-1524710767000 stored as bytes in memory (estimated size 377.0 B, free 413.4 MB)
2018-04-25 22:46:07 INFO  BlockManagerInfo:54 - Added input-0-1524710767000 in memory on 10.0.2.15:45765 (size: 377.0 B, free: 413.8 MB)
2018-04-25 22:46:07 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:07 WARN  BlockManager:66 - Block input-0-1524710767000 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:07 INFO  BlockGenerator:54 - Pushed block input-0-1524710767000
2018-04-25 22:46:07 INFO  PythonRunner:54 - Times: total = 21, boot = -19, init = 36, finish = 4
2018-04-25 22:46:07 INFO  PythonRunner:54 - Times: total = 50, boot = -56, init = 106, finish = 0
2018-04-25 22:46:07 INFO  Executor:54 - Finished task 1.0 in stage 10.0 (TID 49). 1267 bytes result sent to driver
2018-04-25 22:46:07 INFO  TaskSetManager:54 - Starting task 2.0 in stage 10.0 (TID 50, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:46:07 INFO  TaskSetManager:54 - Finished task 1.0 in stage 10.0 (TID 49) in 339 ms on localhost (executor driver) (2/5)
2018-04-25 22:46:07 INFO  Executor:54 - Running task 2.0 in stage 10.0 (TID 50)
2018-04-25 22:46:07 INFO  BlockManager:54 - Found block input-0-1524710757200 locally
2018-04-25 22:46:07 INFO  PythonRunner:54 - Times: total = 81, boot = -62, init = 143, finish = 0
Traceback (most recent call last):
  File "/home/rjha/stream-benchmarking-scratch/streaming_test.py", line 31, in <module>
    ssc.awaitTermination()
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/streaming/context.py", line 206, in awaitTermination
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 1158, in __call__
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 908, in send_command
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 1055, in send_command
  File "/usr/lib/python2.7/socket.py", line 451, in readline
    data = self._sock.recv(self._rbufsize)
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/context.py", line 234, in signal_handler
KeyboardInterrupt
2018-04-25 22:46:07 INFO  PythonRunner:54 - Times: total = 134, boot = 31, init = 94, finish = 9
2018-04-25 22:46:07 INFO  MemoryStore:54 - Block input-0-1524710767200 stored as bytes in memory (estimated size 428.0 B, free 413.4 MB)
2018-04-25 22:46:07 INFO  BlockManagerInfo:54 - Added input-0-1524710767200 in memory on 10.0.2.15:45765 (size: 428.0 B, free: 413.8 MB)
2018-04-25 22:46:07 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:07 WARN  BlockManager:66 - Block input-0-1524710767200 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:07 INFO  BlockGenerator:54 - Pushed block input-0-1524710767200
2018-04-25 22:46:07 INFO  TaskSchedulerImpl:54 - Cancelling stage 0
2018-04-25 22:46:07 INFO  Executor:54 - Finished task 2.0 in stage 10.0 (TID 50). 1267 bytes result sent to driver
2018-04-25 22:46:07 INFO  MemoryStore:54 - Block input-0-1524710767400 stored as bytes in memory (estimated size 360.0 B, free 413.4 MB)
2018-04-25 22:46:07 INFO  TaskSchedulerImpl:54 - Stage 0 was cancelled
2018-04-25 22:46:07 INFO  BlockManagerInfo:54 - Added input-0-1524710767400 in memory on 10.0.2.15:45765 (size: 360.0 B, free: 413.8 MB)
2018-04-25 22:46:07 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:07 WARN  BlockManager:66 - Block input-0-1524710767400 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:07 INFO  BlockGenerator:54 - Pushed block input-0-1524710767400
2018-04-25 22:46:07 INFO  StreamingContext:54 - Invoking stop(stopGracefully=false) from shutdown hook
2018-04-25 22:46:07 INFO  TaskSetManager:54 - Starting task 3.0 in stage 10.0 (TID 51, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:46:07 INFO  Executor:54 - Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled
2018-04-25 22:46:07 INFO  Executor:54 - Running task 3.0 in stage 10.0 (TID 51)
2018-04-25 22:46:07 INFO  BlockManager:54 - Found block input-0-1524710757400 locally
2018-04-25 22:46:07 INFO  TaskSetManager:54 - Finished task 2.0 in stage 10.0 (TID 50) in 406 ms on localhost (executor driver) (3/5)
2018-04-25 22:46:07 INFO  DAGScheduler:54 - ResultStage 0 (start at NativeMethodAccessorImpl.java:0) failed in 16.795 s due to Job 0 cancelled as part of cancellation of all jobs
2018-04-25 22:46:07 WARN  ReceiverTracker:66 - Receiver 0 exited but didn't deregister
2018-04-25 22:46:07 INFO  ReceiverSupervisorImpl:54 - Received stop signal
2018-04-25 22:46:07 INFO  PythonRunner:54 - Times: total = 65, boot = -129, init = 194, finish = 0
2018-04-25 22:46:07 INFO  PythonRunner:54 - Times: total = 59, boot = -124, init = 183, finish = 0
2018-04-25 22:46:07 INFO  ReceiverTracker:54 - Sent stop signal to all 0 receivers
2018-04-25 22:46:07 INFO  MemoryStore:54 - Block input-0-1524710767600 stored as bytes in memory (estimated size 332.0 B, free 413.4 MB)
2018-04-25 22:46:07 INFO  Executor:54 - Finished task 3.0 in stage 10.0 (TID 51). 1267 bytes result sent to driver
2018-04-25 22:46:07 INFO  ReceiverSupervisorImpl:54 - Stopping receiver with message: Stopped by driver: 
2018-04-25 22:46:07 INFO  ReceiverTracker:54 - All of the receivers have deregistered successfully
2018-04-25 22:46:07 INFO  ReceiverTracker:54 - ReceiverTracker stopped
2018-04-25 22:46:07 INFO  SocketReceiver:54 - Closed socket to localhost:9998
2018-04-25 22:46:07 INFO  ReceiverSupervisorImpl:54 - Called receiver onStop
2018-04-25 22:46:07 INFO  ReceiverSupervisorImpl:54 - Deregistering receiver 0
2018-04-25 22:46:07 INFO  TaskSchedulerImpl:54 - Cancelling stage 10
2018-04-25 22:46:07 INFO  TaskSchedulerImpl:54 - Stage 10 was cancelled
2018-04-25 22:46:07 INFO  DAGScheduler:54 - ResultStage 10 (call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257) failed in 1.196 s due to Job 16 cancelled as part of cancellation of all jobs
2018-04-25 22:46:07 INFO  BlockManagerInfo:54 - Added input-0-1524710767600 in memory on 10.0.2.15:45765 (size: 332.0 B, free: 413.8 MB)
2018-04-25 22:46:07 INFO  DAGScheduler:54 - Job 16 failed: call at /home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py:2257, took 1.301276 s
2018-04-25 22:46:07 WARN  SocketReceiver:87 - Error receiving data
java.net.SocketException: Socket closed
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.getNext(SocketInputDStream.scala:121)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.getNext(SocketInputDStream.scala:119)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:91)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:72)
2018-04-25 22:46:07 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.
2018-04-25 22:46:07 WARN  BlockManager:66 - Block input-0-1524710767600 replicated to only 0 peer(s) instead of 1 peers
2018-04-25 22:46:07 ERROR BlockGenerator:91 - Error in block pushing thread
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:205)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.streaming.receiver.ReceiverSupervisorImpl.pushAndReportBlock(ReceiverSupervisorImpl.scala:162)
	at org.apache.spark.streaming.receiver.ReceiverSupervisorImpl.pushArrayBuffer(ReceiverSupervisorImpl.scala:129)
	at org.apache.spark.streaming.receiver.ReceiverSupervisorImpl$$anon$2.onPushBlock(ReceiverSupervisorImpl.scala:110)
	at org.apache.spark.streaming.receiver.BlockGenerator.pushBlock(BlockGenerator.scala:297)
	at org.apache.spark.streaming.receiver.BlockGenerator.org$apache$spark$streaming$receiver$BlockGenerator$$keepPushingBlocks(BlockGenerator.scala:269)
	at org.apache.spark.streaming.receiver.BlockGenerator$$anon$1.run(BlockGenerator.scala:110)
Caused by: org.apache.spark.SparkException: Could not find ReceiverTracker.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:135)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:229)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:523)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:91)
	... 7 more
2018-04-25 22:46:07 ERROR ReceiverSupervisorImpl:70 - Error stopping receiver 0 org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:205)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.streaming.receiver.ReceiverSupervisorImpl.onReceiverStop(ReceiverSupervisorImpl.scala:197)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:172)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisorImpl$$anon$1$$anonfun$receive$1.applyOrElse(ReceiverSupervisorImpl.scala:82)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Could not find ReceiverTracker.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:135)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:229)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:523)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:91)
	... 12 more

2018-04-25 22:46:07 INFO  TaskSetManager:54 - Finished task 3.0 in stage 10.0 (TID 51) in 329 ms on localhost (executor driver) (4/5)
2018-04-25 22:46:07 INFO  TaskSchedulerImpl:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-04-25 22:46:07 INFO  JobGenerator:54 - Stopping JobGenerator immediately
2018-04-25 22:46:07 WARN  ReceiverSupervisorImpl:87 - Restarting receiver with delay 2000 ms: Error receiving data
java.net.SocketException: Socket closed
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.getNext(SocketInputDStream.scala:121)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.getNext(SocketInputDStream.scala:119)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:91)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:72)
2018-04-25 22:46:08 INFO  ReceiverSupervisorImpl:54 - Stopping receiver with message: Restarting receiver with delay 2000ms: Error receiving data: java.net.SocketException: Socket closed
2018-04-25 22:46:08 WARN  ReceiverSupervisorImpl:66 - Receiver has been stopped
2018-04-25 22:46:08 INFO  RecurringTimer:54 - Stopped timer for JobGenerator after time 1524710768000
2018-04-25 22:46:08 INFO  BlockGenerator:54 - Stopping BlockGenerator
2018-04-25 22:46:08 INFO  JobScheduler:54 - Finished job streaming job 1524710758000 ms.1 from job set of time 1524710758000 ms
2018-04-25 22:46:08 INFO  JobScheduler:54 - Starting job streaming job 1524710759000 ms.0 from job set of time 1524710759000 ms
2018-04-25 22:46:08 ERROR JobScheduler:91 - Error running job streaming job 1524710758000 ms.1
org.apache.spark.SparkException: An exception was raised by Python:
Traceback (most recent call last):
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/streaming/util.py", line 65, in call
    r = self.func(t, *rdds)
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/streaming/dstream.py", line 159, in <lambda>
    func = lambda t, rdd: old_func(rdd)
  File "/home/rjha/stream-benchmarking-scratch/streaming_test.py", line 28, in <lambda>
    w_2_ts.foreachRDD(lambda rdd: rdd.foreach(print_dp))
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/rdd.py", line 797, in foreach
    self.mapPartitions(processPartition).count()  # Force evaluation
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/rdd.py", line 1056, in count
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/rdd.py", line 1047, in sum
    return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add)
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/rdd.py", line 921, in fold
    vals = self.mapPartitions(func).collect()
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/rdd.py", line 824, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 1160, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/rjha/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py", line 320, in get_return_value
    format(target_id, ".", name), value)
Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job 16 cancelled as part of cancellation of all jobs
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1539)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:735)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:735)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:735)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:735)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1792)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:938)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:153)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:748)


	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-04-25 22:46:08 INFO  JobScheduler:54 - Added jobs for time 1524710768000 ms
2018-04-25 22:46:08 INFO  JobGenerator:54 - Stopped JobGenerator
Exception in thread Thread-1 (most likely raised during interpreter shutdown):
Traceback (most recent call last):
  File "/usr/lib/python2.7/threading.py", line 801, in __bootstrap_inner
  File "/usr/lib/python2.7/threading.py", line 754, in run
  File "/usr/lib/python2.7/SocketServer.py", line 236, in serve_forever
  File "/usr/lib/python2.7/threading.py", line 585, in set
  File "/usr/lib/python2.7/threading.py", line 407, in notifyAll
<type 'exceptions.TypeError'>: 'NoneType' object is not callable
2018-04-25 22:46:08 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:08 INFO  RecurringTimer:54 - Stopped timer for BlockGenerator after time 1524710768400
2018-04-25 22:46:08 INFO  BlockGenerator:54 - Waiting for block pushing thread to terminate
2018-04-25 22:46:08 INFO  BlockGenerator:54 - Stopped BlockGenerator
2018-04-25 22:46:08 INFO  ReceiverSupervisorImpl:54 - Stopped receiver without error
2018-04-25 22:46:08 INFO  Executor:54 - Executor killed task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled
2018-04-25 22:46:08 INFO  JobScheduler:54 - Finished job streaming job 1524710759000 ms.0 from job set of time 1524710759000 ms
2018-04-25 22:46:08 INFO  JobScheduler:54 - Starting job streaming job 1524710759000 ms.1 from job set of time 1524710759000 ms
2018-04-25 22:46:08 INFO  JobScheduler:54 - Finished job streaming job 1524710759000 ms.1 from job set of time 1524710759000 ms
2018-04-25 22:46:08 WARN  TaskSetManager:66 - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): TaskKilled (Stage cancelled)
2018-04-25 22:46:08 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-04-25 22:46:08 INFO  JobScheduler:54 - Starting job streaming job 1524710760000 ms.0 from job set of time 1524710760000 ms
2018-04-25 22:46:08 ERROR JobScheduler:91 - Error running job streaming job 1524710759000 ms.0
py4j.Py4JException: Error while sending a command.
	at py4j.CallbackClient.sendCommand(CallbackClient.java:357)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:316)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy16.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: py4j.Py4JNetworkException
	at py4j.CallbackConnection.sendCommand(CallbackConnection.java:138)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:344)
	... 24 more
2018-04-25 22:46:08 INFO  JobScheduler:54 - Finished job streaming job 1524710760000 ms.0 from job set of time 1524710760000 ms
2018-04-25 22:46:08 INFO  JobScheduler:54 - Starting job streaming job 1524710760000 ms.1 from job set of time 1524710760000 ms
2018-04-25 22:46:08 INFO  JobScheduler:54 - Finished job streaming job 1524710760000 ms.1 from job set of time 1524710760000 ms
2018-04-25 22:46:08 INFO  JobScheduler:54 - Starting job streaming job 1524710761000 ms.0 from job set of time 1524710761000 ms
2018-04-25 22:46:08 ERROR JobScheduler:91 - Error running job streaming job 1524710759000 ms.1
py4j.Py4JException: Error while sending a command.
	at py4j.CallbackClient.sendCommand(CallbackClient.java:357)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:316)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy16.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: py4j.Py4JNetworkException
	at py4j.CallbackConnection.sendCommand(CallbackConnection.java:138)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:344)
	... 24 more
2018-04-25 22:46:08 INFO  JobScheduler:54 - Finished job streaming job 1524710761000 ms.0 from job set of time 1524710761000 ms
2018-04-25 22:46:08 INFO  JobScheduler:54 - Starting job streaming job 1524710761000 ms.1 from job set of time 1524710761000 ms
2018-04-25 22:46:08 INFO  JobScheduler:54 - Finished job streaming job 1524710761000 ms.1 from job set of time 1524710761000 ms
2018-04-25 22:46:08 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2018-04-25 22:46:08 INFO  DAGScheduler:54 - Got job 17 (runJob at SparkHadoopWriter.scala:78) with 5 output partitions
2018-04-25 22:46:08 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (runJob at SparkHadoopWriter.scala:78)
2018-04-25 22:46:08 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-04-25 22:46:08 INFO  DAGScheduler:54 - Missing parents: List()
2018-04-25 22:46:08 INFO  DAGScheduler:54 - Submitting ResultStage 11 (MapPartitionsRDD[71] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 258
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 272
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 268
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 261
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 270
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 273
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 264
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 259
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 257
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 266
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 275
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 274
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 251
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 260
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 262
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 255
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 269
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 265
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 271
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 252
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 263
2018-04-25 22:46:08 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 10.0.2.15:45765 in memory (size: 4.1 KB, free: 413.8 MB)
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 254
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 253
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 256
2018-04-25 22:46:08 INFO  ContextCleaner:54 - Cleaned accumulator 267
2018-04-25 22:46:08 INFO  JobScheduler:54 - Stopped JobScheduler
2018-04-25 22:46:08 INFO  ContextHandler:910 - Stopped o.s.j.s.ServletContextHandler@20d2fce4{/streaming,null,UNAVAILABLE,@Spark}
2018-04-25 22:46:08 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 75.4 KB, free 413.3 MB)
2018-04-25 22:46:08 INFO  ContextHandler:910 - Stopped o.s.j.s.ServletContextHandler@42a46489{/streaming/batch,null,UNAVAILABLE,@Spark}
2018-04-25 22:46:08 INFO  ContextHandler:910 - Stopped o.s.j.s.ServletContextHandler@72771032{/static/streaming,null,UNAVAILABLE,@Spark}
2018-04-25 22:46:08 INFO  StreamingContext:54 - StreamingContext stopped successfully
2018-04-25 22:46:08 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2018-04-25 22:46:08 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 27.9 KB, free 413.3 MB)
2018-04-25 22:46:08 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 10.0.2.15:45765 (size: 27.9 KB, free: 413.7 MB)
2018-04-25 22:46:08 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039
2018-04-25 22:46:08 INFO  DAGScheduler:54 - Submitting 5 missing tasks from ResultStage 11 (MapPartitionsRDD[71] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2018-04-25 22:46:08 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 5 tasks
2018-04-25 22:46:08 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 52, localhost, executor driver, partition 0, ANY, 7772 bytes)
2018-04-25 22:46:08 INFO  TaskSetManager:54 - Starting task 1.0 in stage 11.0 (TID 53, localhost, executor driver, partition 1, ANY, 7772 bytes)
2018-04-25 22:46:08 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 52)
2018-04-25 22:46:08 INFO  Executor:54 - Running task 1.0 in stage 11.0 (TID 53)
2018-04-25 22:46:08 INFO  BlockManager:54 - Found block input-0-1524710758000 locally
2018-04-25 22:46:08 INFO  BlockManager:54 - Found block input-0-1524710757800 locally
2018-04-25 22:46:08 INFO  AbstractConnector:318 - Stopped Spark@1711e0a3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-04-25 22:46:08 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:08 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.2.15:4040
2018-04-25 22:46:08 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2018-04-25 22:46:08 INFO  PythonRunner:54 - Times: total = 63, boot = -859, init = 922, finish = 0
2018-04-25 22:46:08 INFO  PythonRunner:54 - Times: total = 54, boot = -908, init = 962, finish = 0
2018-04-25 22:46:08 INFO  DAGScheduler:54 - Job 17 failed: runJob at SparkHadoopWriter.scala:78, took 0.266497 s
2018-04-25 22:46:08 ERROR SparkHadoopWriter:91 - Aborting job job_20180425224608_0071.
org.apache.spark.SparkException: Job 17 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:837)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:835)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:835)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1838)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1751)
	at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1924)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1923)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:572)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1988)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2080)
	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1493)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1472)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1472)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1472)
	at org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:550)
	at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:748)
2018-04-25 22:46:09 INFO  DAGScheduler:54 - ResultStage 11 (runJob at SparkHadoopWriter.scala:78) failed in 0.233 s due to Stage cancelled because SparkContext was shut down
2018-04-25 22:46:09 INFO  PythonRunner:54 - Times: total = 69, boot = 29, init = 40, finish = 0
2018-04-25 22:46:09 INFO  FileOutputCommitter:535 - Saved output of task 'attempt_20180425224608_0071_m_000001_0' to file:/home/rjha/stream-benchmarking-scratch/text-1524710759000/_temporary/0/task_20180425224608_0071_m_000001
2018-04-25 22:46:09 INFO  SparkHadoopMapRedUtil:54 - attempt_20180425224608_0071_m_000001_0: Committed
2018-04-25 22:46:09 INFO  Executor:54 - Finished task 1.0 in stage 11.0 (TID 53). 1572 bytes result sent to driver
2018-04-25 22:46:09 INFO  TaskSetManager:54 - Starting task 2.0 in stage 11.0 (TID 54, localhost, executor driver, partition 2, ANY, 7772 bytes)
2018-04-25 22:46:09 INFO  TaskSetManager:54 - Finished task 1.0 in stage 11.0 (TID 53) in 200 ms on localhost (executor driver) (1/5)
2018-04-25 22:46:09 INFO  Executor:54 - Running task 2.0 in stage 11.0 (TID 54)
2018-04-25 22:46:09 INFO  PythonRunner:54 - Times: total = 67, boot = 19, init = 48, finish = 0
2018-04-25 22:46:09 INFO  SparkHadoopMapRedUtil:54 - No need to commit output of task because needsTaskCommit=false: attempt_20180425224608_0071_m_000000_0
2018-04-25 22:46:09 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 52). 1615 bytes result sent to driver
2018-04-25 22:46:09 ERROR TaskSchedulerImpl:91 - Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@4d7e2c7f rejected from java.util.concurrent.ThreadPoolExecutor@9f62a08[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 53]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:413)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:394)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-04-25 22:46:09 INFO  TaskSetManager:54 - Starting task 3.0 in stage 11.0 (TID 55, localhost, executor driver, partition 3, ANY, 7772 bytes)
2018-04-25 22:46:09 ERROR Inbox:91 - Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@5e913067 rejected from java.util.concurrent.ThreadPoolExecutor@7aa624e4[Shutting down, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 53]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:177)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:87)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1.apply(LocalSchedulerBackend.scala:85)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:85)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:70)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-04-25 22:46:09 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-04-25 22:46:09 INFO  BlockManager:54 - Found block input-0-1524710758200 locally
2018-04-25 22:46:09 INFO  MemoryStore:54 - MemoryStore cleared
2018-04-25 22:46:09 INFO  BlockManager:54 - BlockManager stopped
2018-04-25 22:46:09 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-04-25 22:46:09 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-04-25 22:46:09 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-04-25 22:46:10 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-04-25 22:46:10 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-4b6a90be-4821-4af8-9089-88245154db40
2018-04-25 22:46:10 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a9a98e64-a528-4051-8500-b89c9bf0f7a2/pyspark-6c05a674-b507-4fa3-83db-c340afc2949d
2018-04-25 22:46:10 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a9a98e64-a528-4051-8500-b89c9bf0f7a2
